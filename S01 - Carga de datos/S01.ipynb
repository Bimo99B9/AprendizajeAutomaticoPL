{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 1 - Carga de datos\n",
    "En esta práctica vamos a ver cómo cargar datos en un programa para poder posteriormente entrenar algoritmos de aprendizaje automático con los mismos. Esencialmente vamos a ver tres manera de incorporar datos a un programa:\n",
    "1. Utilizando los conjuntos de datos de ejemplo que vienen en la librería `scikit-learn`\n",
    "2. Generando conjuntos artificiales\n",
    "3. Leyendo datos que tengamos en ficheros de texto o en hojas de cálculo\n",
    "\n",
    "Por supuesto, existen otras maneras de incorporar datos a nuestros programas, como pueden ser la incorporación directa desde una base de datos utilizando la API adecuada o la lectura desde otro formato de fichero. Sin embargo, para los objetivos de esta asignatura los tres métodos explicados serán más que suficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Conjuntos de datos de la librería `scikit-learn`\n",
    "`sklearn` dispone de una serie de conjuntos de datos de ejemplos que podemos cargar rápidamente para empezar a hacer pruebas con ellos. En <https://scikit-learn.org/stable/datasets.html> podéis acceder a un listado de los mismos.\n",
    "\n",
    "Lo que nos interesa en este caso son los `Toy datasets` y los `Real world datasets`. Los primeros son conjuntos pequeños que suelen utilizarse cuando nos estamos iniciando en el Aprendizaje Automático, como es el caso. Los segundos, son problemas clásicos, ampliamente conocidos, con bastantes ejemplos y con ciertas particularidades que los hacen un poco más difíciles o adecuados para tareas un poco más complejas dentro del Aprendizaje Automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tendremos que hacer para cargar uno de estos conjuntos es incorporar el módulo `datasets` de la librería `scikit-learn`. Desde este módulo tendremos acceso a todo lo relativo con la carga y generación de datos dentro de la librería.\n",
    "\n",
    "Por tanto, ya podemos cargar un conjunto de datos. La intrucción para cargar un conjunto será la llamada a la función `load_X()` correspondiente, donde `X` debe sustituirse por el nombre del conjunto que queramos cargar. \n",
    "\n",
    "En este caso vamos a cargar el conjuto de los lirios, cuyo nombre es `iris`, con lo que la función será `load_iris()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargamos el módulo datasets de la librería scikit-learn\n",
    "from sklearn import datasets\n",
    "\n",
    "# Cargamos el conjunto de los lirios\n",
    "cjto = datasets.load_iris()\n",
    "\n",
    "display(type(cjto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podéis ver, la función `load_X()` devuelve un objeto de tipo `Bunch` que contiene muchas cosas pero básicamente nos interesan tres: i) los datos tomados para cada uno de los ejemplo (`data`), la clase de esos ejemplos (`target`) y la descripción del conjunto de datos (`DESCR`).\n",
    "\n",
    "En los Notebooks podemos utilizar las instrucciones `display()` y `print()` para mostrar el contenido de variables. La salida que ofrece `display()` presenta para algunas variables un formato más visual, así que a veces utilizaremos esta instrucción. En los scripts o programas que hagamos utilizaremos `print()` puesto que `display()` solo funciona en los notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Número de ejemplos: 150\n",
      "Número de atributos: 4\n"
     ]
    }
   ],
   "source": [
    "# almacenamos en la variable X los datos tomados para cada uno de los ejemplos\n",
    "X = cjto.data\n",
    "display(type(X))\n",
    "print(X)\n",
    "\n",
    "# obtenemos el número de ejemplos y el número de atributos\n",
    "n_samples, n_features = X.shape\n",
    "print(\"Número de ejemplos:\", n_samples)\n",
    "print(\"Número de atributos:\", n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, la variable `X` contendrá un array de `numpy` de dos dimensiones, del cual podremos obtener el número de ejemplos y el número de atributos.\n",
    "\n",
    "La clase de los ejemplos podemos extraerla de la propiedad `target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# cargamos la clase de los ejemplos en una variable\n",
    "Y = cjto.target\n",
    "display(type(Y))\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiésemos obtener una descripción del conjunto de datos que acabamos de cargar bastaría con la siguiente instrucción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# almacenamos la clase en una variable\n",
    "print(cjto.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generando conjuntos artificiales\n",
    "A veces nos interesa crear conjuntos de datos artificiales para comprobar el rendimiento de un algoritmo frente a datos que cumplan unas determinadas características. Vamos a ver cómo podemos genera conjuntos de ejemplos de regresión (cuando se trata de predecir un número) y conjuntos de clasificación (cuando se quiere predecir una categoría).\n",
    "\n",
    "### 1.2.1 Generando un conjunto de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes:\n",
      " [56.67437567 44.75931499  0.        ]\n",
      "Matriz de datos:\n",
      " [[-1.29805747 -0.62438707  1.83593197]\n",
      " [-0.03490065 -0.03170317 -0.32389249]\n",
      " [ 0.96395357  1.48788051  1.33981505]\n",
      " [ 0.15998564 -1.19323512  0.24830464]]\n",
      "Clase:\n",
      " [-101.51373397   -3.39698472  121.22797913  -44.34130059]\n"
     ]
    }
   ],
   "source": [
    "# es necesario importar el módulo datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# se utiliza la función 'make_regression'\n",
    "X, Y, coeficientes = datasets.make_regression(n_samples=20, n_features=3, \n",
    "                                                n_informative=2, n_targets=1, coef=True)\n",
    "\n",
    "print(\"Coeficientes:\\n\", coeficientes)\n",
    "print(\"Matriz de datos:\\n\", X[:4])\n",
    "print(\"Clase:\\n\", Y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior se puede ver un ejemplo de utilización de la función `make_regression` que generará un conjunto de datos de regresión donde la clase será un valor real. Además le estamos especificando que genere 20 ejemplos (`n_samples`) con 3 atributos cada uno (`n_features`) donde únicamente 2 de esos 3 atributos tendrán relevancia para el cálculo de la clase (`n_informative`). Además se le indica que la clase de un ejemplo será un solo número (`n_targets`) y que queremos que retorne los coeficientes con los que ha calculado la clase (`coef=True`).\n",
    "\n",
    "Esta función tiene muchos más parámetros que pueden utilizarse para crear conjuntos de datos a nuestra medida.\n",
    "En <https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression> se puede encontrar una descripción más detallada de todos sus parámetros.\n",
    "\n",
    "Si ejecutáis el código anterior varias veces, observaréis que en cada ejecución se genera un conjunto de datos diferente. Si no quisiésemos que esto fuese así, se debería utilizar el parámetro `random_state` y así garantizar que la salida de la función se reproducirá en cada ejecución.\n",
    "\n",
    "Se ha limitado la salida a 4 casos (`[:4]`) para que no sea demasiado larga.\n",
    "\n",
    "### 1.2.2 Generando un conjunto de clasificación\n",
    "Vamos a generar ahora un conjunto de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de datos:\n",
      " [[-1.14039656 -1.362421    0.68151442]\n",
      " [-1.89992685 -0.0333128  -1.08717286]\n",
      " [-0.69809106  1.97260753 -2.37195417]\n",
      " [-1.20133633  0.47282464 -1.17824111]]\n",
      "Clase:\n",
      " [0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# el módulo datasets debe estar cargado\n",
    "\n",
    "X, Y = datasets.make_classification(n_samples=20, n_features=3, n_informative=2, n_redundant=1, \n",
    "                                    n_classes=2, weights=[0.8, 0.2])\n",
    "\n",
    "print(\"Matriz de datos:\\n\", X[:4])\n",
    "print(\"Clase:\\n\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hemos generado de nuevo 20 ejemplos con 3 atributos donde 2 son importantes para predecir la clase y, además, hay un atributo redundante (será una combinación lineal de los otros dos). Se le indica también que los ejemplos pertenecerán a 2 clases posibles (`n_classes`) y habrá un 80% de ejemplos de una clase y un 20% de la otra (`weights`).\n",
    "\n",
    "Podéis encontrar más información sobre esta función en <https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification>\n",
    "\n",
    "## 1.3 Cargando datos desde ficheros\n",
    "Vamos a ver ahora cómo podemos cargar datos desde un fichero de texto y desde una hoja de cálculo.\n",
    "\n",
    "Para ello vamos a utilizar una nueva librería, `pandas`, sobre la que volveremos en futuras sesiones.\n",
    "\n",
    "### 1.3.1 Desde un fichero de texto\n",
    "\n",
    "Para leer datos desde ficheros de texto, una de las formas más efectivas es mediante el uso de la función `read_csv`de la librería `pandas`. Esta función, como su nombre indica, está pensada para la lectura de ficheros de texto en formato CSV (comma-separated values), sin embargo, asignado los argumentos adecuados a sus parámetros podremos leer datos de cualquier fichero de texto.\n",
    "\n",
    "Vamos a ver cómo cargar el fichero **Container_Crane_Controller_Data_Set.csv** que tenéis en el directorio y que ha sido obtenido del *Machine Learning Repository* de la UCI (Universidad de California en Irvine): <https://archive.ics.uci.edu/ml/datasets/Container+Crane+Controller+Data+Set>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speed  Angle  Power\n",
      "0       1     -5    0.3\n",
      "1       2      5    0.3\n",
      "2       3     -2    0.5\n",
      "3       1      2    0.5\n",
      "4       2      0    0.7\n",
      "5       6     -5    0.5\n",
      "6       7      5    0.5\n",
      "7       6     -2    0.3\n",
      "8       7      2    0.3\n",
      "9       6      0    0.7\n",
      "10      8     -5    0.5\n",
      "11      9      5    0.5\n",
      "12     10     -2    0.3\n",
      "13      8      2    0.3\n",
      "14      9      0    0.5\n"
     ]
    }
   ],
   "source": [
    "# importamos la librería pandas y le damos el nombre de 'pd'\n",
    "import pandas as pd\n",
    "\n",
    "# procedemos a la carga de los datos contenidos en el fichero de texto utilizando los parámetros adecuados\n",
    "df = pd.read_csv('Container_Crane_Controller_Data_Set.csv', sep=';', header=0, decimal=',')\n",
    "display(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si echáis un vistazo al fichero de texto **Container_Crane_Controller_Data_Set.csv** podréis observar que cada ejemplo está en una línea y que cada atributo está separado por un ';'. Cuenta con una línea de cabecera, donde se indica el nombre de los dos atributos (*Speed* y *Angle*) y de la clase (*Power*). Además, si nos fijamos en la última columna, se está utilizando como separador decimal la ','. \n",
    "\n",
    "Por todas estas razones, en la llamada a `read_csv` se utilizan los parámetros `sep` (para indicar el separador entre atributos), `header` (para indicar que los nombres de los atributos están en la fila 0) y `decimal` (con el que se indica el separador decimal).\n",
    "\n",
    "En <https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html> se puede encontrar más información sobre cómo utilizar esta función y todos sus parámetros.\n",
    "\n",
    "En este caso vemos que el tipo de la variable `df` es `pandas.core.frame.DataFrame`. Un `DataFrame` es una estructura de almacenamiento muy potente sobre la que trabajaremos en varias sesiones de prácticas más adelante. \n",
    "\n",
    "De momento debemos quedarnos con que `scikit-learn` es capaz de leer datos de un `DataFrame` y con que podemos convertir los datos de un `DataFrame` a arrays de Numpy. Veamos cómo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speed  Angle\n",
      "0       1     -5\n",
      "1       2      5\n",
      "2       3     -2\n",
      "3       1      2\n",
      "4       2      0\n",
      "5       6     -5\n",
      "6       7      5\n",
      "7       6     -2\n",
      "8       7      2\n",
      "9       6      0\n",
      "10      8     -5\n",
      "11      9      5\n",
      "12     10     -2\n",
      "13      8      2\n",
      "14      9      0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[ 1 -5]\n",
      " [ 2  5]\n",
      " [ 3 -2]\n",
      " [ 1  2]\n",
      " [ 2  0]\n",
      " [ 6 -5]\n",
      " [ 7  5]\n",
      " [ 6 -2]\n",
      " [ 7  2]\n",
      " [ 6  0]\n",
      " [ 8 -5]\n",
      " [ 9  5]\n",
      " [10 -2]\n",
      " [ 8  2]\n",
      " [ 9  0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# separamos las dos primeras columnas y las almacenamos en X\n",
    "X = df.iloc[:,0:2]\n",
    "print(X)\n",
    "print(type(X))\n",
    "\n",
    "# extraemos los datos de X en forma de array de numpy\n",
    "X_np = X.values\n",
    "print(X_np)\n",
    "print(type(X_np))\n",
    "\n",
    "# repetimos las operaciones para obtener la clase de cada ejemplo como DataFrame y como array de numpy\n",
    "Y = df.iloc[:,2]\n",
    "Y_np = Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando `iloc[]` podemos acceder a las filas y columnas que queramos de un `DataFrame`. Utilizando la propiedad `values` podremos tener el contenido del `DataFrame` como un array de dos dimensiones de numpy.\n",
    "\n",
    "### 1.3.2 Cargando datos desde una hoja de cálculo\n",
    "Para realizar esta operación utilizaremos también una función de la librería `pandas` que se llama `read_excel` y que retorna también un `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speed  Angle  Power\n",
      "0       1     -5    0.3\n",
      "1       2      5    0.3\n",
      "2       3     -2    0.5\n",
      "3       1      2    0.5\n",
      "4       2      0    0.7\n",
      "5       6     -5    0.5\n",
      "6       7      5    0.5\n",
      "7       6     -2    0.3\n",
      "8       7      2    0.3\n",
      "9       6      0    0.7\n",
      "10      8     -5    0.5\n",
      "11      9      5    0.5\n",
      "12     10     -2    0.3\n",
      "13      8      2    0.3\n",
      "14      9      0    0.5\n"
     ]
    }
   ],
   "source": [
    "# se importa la librería\n",
    "import pandas as pd\n",
    "\n",
    "# se llama a la función con los parámetros adecuados\n",
    "df = pd.read_excel('Container_Crane_Controller_Data_Set.xlsx', sheet_name='Data', header=0)\n",
    "display(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso le indicamos que lea los datos del fichero **Container_Crane_Controller_Data_Set.xlsx** en la pestaña `'Data'`. Esta hoja de cálculo tiene dos pestañas, una con una descripción del conjunto de datos y otra con los datos, así que debemos indicarle la pestaña de la que debe tomar los datos.\n",
    "\n",
    "Más información sobre esta función podéis encontrarla en: <https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speed  Angle\n",
      "0       1     -5\n",
      "1       2      5\n",
      "2       3     -2\n",
      "3       1      2\n",
      "4       2      0\n",
      "5       6     -5\n",
      "6       7      5\n",
      "7       6     -2\n",
      "8       7      2\n",
      "9       6      0\n",
      "10      8     -5\n",
      "11      9      5\n",
      "12     10     -2\n",
      "13      8      2\n",
      "14      9      0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[ 1 -5]\n",
      " [ 2  5]\n",
      " [ 3 -2]\n",
      " [ 1  2]\n",
      " [ 2  0]\n",
      " [ 6 -5]\n",
      " [ 7  5]\n",
      " [ 6 -2]\n",
      " [ 7  2]\n",
      " [ 6  0]\n",
      " [ 8 -5]\n",
      " [ 9  5]\n",
      " [10 -2]\n",
      " [ 8  2]\n",
      " [ 9  0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# separamos las dos primeras columnas y las almacenamos en X\n",
    "X = df.iloc[:,0:2]\n",
    "print(X)\n",
    "print(type(X))\n",
    "\n",
    "# extraemos los datos de X en forma de array de numpy\n",
    "X_np = X.values\n",
    "print(X_np)\n",
    "print(type(X_np))\n",
    "\n",
    "# repetimos las operaciones para obtener la clase de cada ejemplo como DataFrame y como array de numpy\n",
    "Y = df.iloc[:,2]\n",
    "Y_np = Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "Para practicar lo visto en este notebook deberías hacer uno o varios programas en python (programas, no notebooks) en los que pruebes a cargar conjuntos de datos. Sería recomendable que practicases con todas las formas vistas en este notebook:\n",
    "1. Cargando algún conjunto que ya venga en `scikit-learn`\n",
    "2. Generando un conjunto artificial\n",
    "3. Cargando desde un fichero de texto. Puedes descargar los ficheros con datos de <https://openml.org>, de <https://archive.ics.uci.edu/ml/datasets.php> o de infinidad de sitios en los que hay datos disponibles.\n",
    "4. Cargando datos desde una excel que podéis crear vosotros mismos.\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
