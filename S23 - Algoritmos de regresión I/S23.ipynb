{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 23 - Problemas de Regresión: métricas y regresión lineal\n",
    "\n",
    "A lo largo de la asignatura hemos estado introduciendo conceptos y algoritmos de aprendizaje automático apoyándonos en problemas de clasificación.\n",
    "\n",
    "En esta sesión vamos a introducir otro tipo de problemas, los de regresión, que son problemas en los que en lugar de predecir una categoría debemos predecir un valor continuo.\n",
    "\n",
    "Lo primero que vamos a hacer es plantear un problema muy sencillo en el que los ejemplos vendrán definidos por un solo atributo y nuestro objetivo será tratar de predecir el valor $y$ correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Crear conjunto')\n",
    "print('##########################################')\n",
    "\n",
    "# definimos la función verdadera, a partir de la cual crearemos los conjuntos\n",
    "def fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "# definimos el número de ejemplos del conjunto de entrenamiento y de test\n",
    "num_ejemplos_train = 30\n",
    "num_ejemplos_test = 100\n",
    "\n",
    "# fijamos semilla de aletorios\n",
    "np.random.seed(1234)\n",
    "\n",
    "# creamos valores de X aleatorios para train\n",
    "X_train = np.sort(np.random.rand(num_ejemplos_train))\n",
    "\n",
    "# calculamos los valores de y añadiendo un poco de ruido\n",
    "y_train = fun(X_train) + np.random.randn(num_ejemplos_train) * 0.3\n",
    "\n",
    "# creamos un conjunto de test con num_ejemplos_test ejemplos a igual distancia unos de otros en el intervalo de 0 a 1\n",
    "X_test = np.linspace(0, 1, num_ejemplos_test)\n",
    "\n",
    "# calculamos su valor correcto\n",
    "y_test = fun(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el trozo de código anterior se define un conjunto de datos que sigue la función $y=cos(1.5\\pi x)$, estando los ejemplos representados por un único atributo.\n",
    "\n",
    "Para dificultar un poco el aprendizaje, a la hora de calcular `y_train` incorporamos un poco de ruido. \n",
    "\n",
    "Vamos a representar los datos del conjunto de entrenamiento de forma gráfica acompañados de la función verdadera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### Representamos los datos')\n",
    "print('##########################################')\n",
    "\n",
    "# represento la función verdadera, los ejemplos de entrenamiento y la predicción del modelo\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_test, fun(X_test), label=\"función verdadera\")\n",
    "ax.scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"ejemplos\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Conjunto de datos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos apreciar, el ruido que hemos incorporado a los datos provoca que los ejemplos no se ajusten prefectamente a la función.\n",
    "\n",
    "## 23.1 Baselines de regresión\n",
    "\n",
    "Al igual que sucedía con los problemas de clasificación, es importante tener algún predictor sencillo que sirva para marcar un umbral a partir del cual, rendimientos superiores indiquen que los sistemas están realmente aprendiendo algo.\n",
    "\n",
    "En el caso de la regresión, un baseline sencillo es el *sistema media*, que consiste en calcular el valor medio de $y$ en el conjunto de entrenamiento y utilizarlo como valor constante a predecir para todos los ejemplos del conjunto de test. Esto es precisamente lo que hace `DummyRegressor` cuando utilizamos como estrategia `strategy=\"mean\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### DummyRegressor')\n",
    "print('##########################################')\n",
    "\n",
    "# se crea el sistema que siempre predice la media\n",
    "sys_dummy = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# se entrena con el conjunto de entrenamiento (reshape es para darle ponerlo en forma (num_ejemplos_train,1))\n",
    "sys_dummy.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "# se evalúa sobre el conjunto de test (reshape es para darle ponerlo en forma (num_ejemplos_test,1))\n",
    "y_pred = sys_dummy.predict(X_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos tenido que utilizar `reshape(-1,1)` ya que `X_train` es un vector $(n,)$ y queremos convertirlo a una matriz $(n,1)$.\n",
    "\n",
    "Como vemos en el código, la manera de entrenar y predecir es igual que en los problemas de clasificación.\n",
    "\n",
    "En https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html?highlight=dummyregressos#sklearn.dummy.DummyRegressor.score se pueden encontrar más detalles acerca del sistema `DummyRegressor`.\n",
    "\n",
    "Admite las estrategias:\n",
    "- `mean`, predice la media calculada en el conjunto de entrenamiento.\n",
    "- `median`, predice la mediana calculada en el conjunto de entrenamiento.\n",
    "- `quantile`, predice el cuantil especificado del conjunto de entrenamiento. Debe especificarse en el parámetro `quantile` que debe ser un valor en el rango [0.0, 1.0].\n",
    "- `constant`, predice un valor constante que debe suministrarse en el parámetro `constant`.\n",
    "\n",
    "Vamos a representar gráficamente la solución propuesta por el `DummyRegressor` entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### Representación gráfica')\n",
    "print('##########################################')\n",
    "\n",
    "# represento la función verdadera, los ejemplos de entrenamiento y la predicción del modelo\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_test, fun(X_test), label=\"función verdadera\")\n",
    "ax.plot(X_test, y_pred, label=\"modelo\")\n",
    "ax.scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"ejemplos\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Sistema Media\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de la representación obtenida para el modelo `DummyRegressor` no parece que el rendimiento que se vaya a obtener sea demasiado bueno ya que, independientemente del valor de $x$, el valor predicho para la $y$ será siempre el mismo valor (en este caso la media calculada en el conjunto de entrenamiento).\n",
    "\n",
    "Vamos a ver cómo medirlo.\n",
    "\n",
    "## 23.2 Métricas utilizadas en regresión\n",
    "\n",
    "En los problemas de regresión la clase es de tipo continuo y por tanto debemos utilizar métricas que sean capaces trabajar con este tipo de valores.\n",
    "\n",
    "Hay muchas métricas para problemas de regresión (https://scikit-learn.org/stable/modules/model_evaluation.html), pero nosotros vamos a comentar las tres más utilizadas.\n",
    "\n",
    "### 23.2.1 Error Absoluto medio\n",
    "\n",
    "Esta es la métrica más sencilla e intuitiva. \n",
    "\n",
    "Definimos el **Error Abdoluto Medio**, conocido habitualmente como *Mean Absolute Error (MAE)* como:\n",
    "\n",
    "$$\n",
    "MAE(y,\\hat{y}) = \\frac{1}{n}\\sum^n_{i=1}\\left|y_i - \\hat{y}_i\\right|\n",
    "$$\n",
    "\n",
    "donde $n$ es el número de ejemplos, $\\hat{y}_i$ es el valor predicho para el i-ésimo ejemplo e $y_i$ es su valor verdadero.\n",
    "\n",
    "Así que esta métrica lo que nos muestra es el error medio que se está comentiendo en todos los ejemplos. Así que una predicción perfecta tendrá un MAE de 0 y predicciones imperfectas tendrán valores mayores que 0 sin tener un límite superior. El MAE no puede ser negativo.\n",
    "\n",
    "Vamos a ver qué MAE tenemos para el `DummyRegressor` con el que obtuvimos `y_pred` anteriormente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calcula el error absoluto medio\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE = %.3f\" % mae )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El MAE penaliza por igual errores grandes y errores pequeños. Por ejemplo, si cometemos dos fallos, errando en uno por 2 unidades y en el otro por 6 unidades, el MAE será 4 ($\\frac{2+6}{2}$); si esos dos fallos hubiesen sido dos errores de 4 unidades el MAE sería el mismo ($\\frac{4+4}{2}$).\n",
    "\n",
    "¿Cuál de las dos situaciones es mejor? En principio eso depende del problema que estemos abordando, pero en general, siempre suele ser deseable penalizar más a los sistemas que cometen errores muy grandes.\n",
    "\n",
    "### 23.2.2 Error Cuadrático Medio\n",
    "\n",
    "Para solucionar el problema que hemos visto en el MAE, podemos elevar al cuadrado los errores y así se penalizará mucho más a los errores más grandes.\n",
    "\n",
    "Para ello, definimos el **Error Cuadrático Medio**, conocido habitualmente como *Mean Squared Error (MSE)*, como:\n",
    "\n",
    "$$\n",
    "MSE(y,\\hat{y}) = \\frac{1}{n}\\sum^n_{i=1}\\left(y_i - \\hat{y}_i\\right)^2\n",
    "$$\n",
    "\n",
    "Al igual que sucedía con el MAE, con el error cuadrático medio, una predicción perfecta tendrá un MSE de 0 y predicciones imperfectas tendrán valores mayores que 0 sin tener un límite superior. El MSE no puede ser negativo.\n",
    "\n",
    "El error cuadrático medio **es la métrica más utilizada en los problemas de regresión**.\n",
    "\n",
    "Para las dos situaciones que comentamos antes obtendríamos como MSE $20=\\left(\\frac{2^2+6^2}{2}\\right)$ y $16=\\left(\\frac{4^2+4^2}{2}\\right)$.\n",
    "\n",
    "Vamos a ver qué MSE tenemos para el `DummyRegressor` con el que obtuvimos `y_pred` anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calcula el error cuadrático medio\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE = %.3f\" % mse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores que obtenemos tanto para MSE como para MAE, sabemos que son mejores cuanto más nos acercamos al 0, pero es complicado saber cuánto de mala es una predicción ya que no están acotadas superiormente.\n",
    "\n",
    "### 23.2.3 Coeficiente de determinación\n",
    "\n",
    "Una métrica que nos puede ayuda en esto es **Coeficiente de Determinación**, que se define como (https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score):\n",
    "\n",
    "$$\n",
    "R^2(y,\\hat{y}) = 1 - \\frac{\\sum^n_{i=1}\\left(y_i - \\hat{y}_i\\right)^2}{\\sum^n_{i=1}\\left(y_i - \\bar{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "donde $\\bar{y}=\\frac{1}{n}\\sum^n_{i=1} y_i$, es decir, es la media de los valores de la clase que tienen los ejemplos **del conjunto de datos que se evalúa**.\n",
    "\n",
    "El coeficiente de determinación calcula la proporción de variación de la clase $y$ que es explicada por la predicción $\\hat{y}$.\n",
    "\n",
    "Con lo que:\n",
    "- una predicción perfecta tendrá un $R^2$ de 1, \n",
    "- malas predicciones podrán tener valores negativos \n",
    "- una predicción constante igual al valor medio de la $y$ de los ejemplos evaluados tendrá un $R^2$ igual a 0. Cuando utilizamos `DummyRegressor(strategy=\"mean\")` podemos pensar que $R^2$ debe ser igual a $0$, por lo que acabamos de explicar, pero no tiene por qué ser así. El sistema media calcula la media de los valores de $y$ **del conjunto de entrenamiento** y la media que interviene en el cálculo del coeficiente de determinación es la media de los valores de $y$ **en el conjunto que se evalúa**. \n",
    "\n",
    "Si tenemos un $R^2$ negativo el resultado es muy malo. Si es en torno al 0, es el equivalente a lo que haría el sistema media y si obtenemos un $R^2$ entre 0 y 1 nuestro sistema habrá aprendido algo útil, que será más útil cuanto más nos acerquemos al 1.\n",
    "\n",
    "Veamos el resultado que obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calcula el coeficiente de determinación\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"R2 = %.3f\" % r2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el resultado es próximo al 0, lo cual era esperable ya que estamos utilizando el sistema media. El resultado no es exactamente 0 porque la media de los valores de $y$ en el conjunto de entrenamiento no es exactamente igual a la media de los valores de $y$ en el conjunto de test.\n",
    "\n",
    "## 23.3 Negative scoring y `KFold`\n",
    "\n",
    "Las métricas que hemos visto en clasificación eran todas métricas en las que cuanto mayor fuese el valor que obteníamos mejor era el rendimiento del sistema.\n",
    "\n",
    "En $R^2$ esto es también así, pero en MAE y MSE sucede al contrario.\n",
    "\n",
    "Como la mayoría de las métricas están orientadas a que mayores valores supongan mejor rendimiento, los procedimientos dentro de `scikit-learn` que tratan de optimizar el rendimiento, como por ejemplo `GridSearchCV()`, tratan de maximizar la métrica que se les indica en el parámetro `scoring`.\n",
    "\n",
    "Por tanto, si queremos utilizar MAE o MSE como `scoring` en alguna función de `sklearn`, debemos utilizar sus versiones \"negadas\": `'neg_mean_absolute_error'` y `'neg_mean_squared_error'`.\n",
    "\n",
    "En el enlace https://scikit-learn.org/stable/modules/model_evaluation.html podéis ver todas las métricas que están en esta misma situación. Podréis identificarlas porque todas comienzan su nombre con `'neg_'`\n",
    "\n",
    "Además, también hay que darse cuenta de que cuando realizábamos una `cross_val_score()`, una `GridSearchCV()` o una `RandomizedSearchCV()` en problemas de clasificación siempre utilizábamos `StratifiedKFolds()` como generador de folds estratificados. En los problemas de regresión **no tiene sentido estratificar** por tanto, utilizaremos `KFolds()` como generador de folds:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold\n",
    "\n",
    "\n",
    "## 23.4 Regresión lineal\n",
    "\n",
    "La regresión lineal es un método muy útil para tratar con problemas de regresión. En `sklearn` se dispone del algoritmo `LinearRegression` que calcula la regresión lineal aplicando el método de mínimos cuadrados, obteniendo los parámetros $w$ y $b$ que permiten realizar predicciones mediante $\\hat{y} = wX+b$.\n",
    "\n",
    "Veamos el resultado que obtenemos en este problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### LinearRegression')\n",
    "print('##########################################')\n",
    "\n",
    "# se crea el sistema que siempre predice la media\n",
    "sys_linr = LinearRegression()\n",
    "\n",
    "# se entrena con el conjunto de entrenamiento (reshape es para darle ponerlo en forma (num_ejemplos_train,1))\n",
    "sys_linr.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "# se evalúa sobre el conjunto de test (reshape es para darle ponerlo en forma (num_ejemplos_test,1))\n",
    "y_pred = sys_linr.predict(X_test.reshape(-1,1))\n",
    "\n",
    "# se calcula el error absoluto medio\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE = %.3f\" % mae )\n",
    "\n",
    "# se calcula el error cuadrático medio\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE = %.3f\" % mse )\n",
    "\n",
    "# se calcula el coeficiente de determinación\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"R2 = %.3f\" % r2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los resultados obtenidos ya podemos intuir que el ajuste de la regresión lineal es mejor que el que teníamos con el sistema media.\n",
    "\n",
    "En https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html hay más información sobre este sistema.\n",
    "\n",
    "Una cualidad interesante de la regresión lineal es que podemos obtener los valores de los parámetros $w$ que nos pueden dar pistas sobre la importancia de cada uno de los atributos. Para acceder a ellos debemos utilizar el atributo `coef_` una vez que el sistema haya sido entrenado. \n",
    "\n",
    "Si queremos conocer el valor resultante para $b$ debemos consultar el atributo `intercept_`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w =\", sys_linr.coef_)\n",
    "print(\"b =\", sys_linr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso solo tenemos un valor en $w$ ya que solo tenemos un atributo.\n",
    "\n",
    "Vamos a representar gráficamente la solución aportada por la regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represento la función verdadera, los ejemplos de entrenamiento y la predicción del modelo\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_test, fun(X_test), label=\"función verdadera\")\n",
    "ax.plot(X_test, y_pred, label=\"modelo\")\n",
    "ax.scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"ejemplos\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.legend(loc=\"best\")\n",
    "titulo = \"Regresión lineal [MSE={:0.3f}]\".format(mse)\n",
    "ax.set_title(titulo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el ajuste de la regresión lineal es mejor que el que teníamos con el sistema media, podemos apreciar que la regresión lineal, al ser lineal, nunca podrá ajustarse correctamente a este conjunto de datos.\n",
    "\n",
    "## 23.5 Regresión polinomial\n",
    "\n",
    "Una solución que se plantea para estos casos es combinar de manera polinómica los atributos del conjunto de datos para posibilitar soluciones no lineales.\n",
    "\n",
    "Esto es algo que no debería resultarnos desconocido puesto que ya lo vimos en la sesión dedicada al *kernel trick*.\n",
    "\n",
    "En este caso, al no estar kernelizada la `LinearRegression` debemos generar esas combinaciones de los atributos de manera explícita utilizando el algoritmo `PolynomialFeatures`: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html?highlight=polynomialfea#sklearn.preprocessing.PolynomialFeatures \n",
    "\n",
    "En el parámetro `degree` debemos indicarle el grado que queremos aplicar y con el parámetro `include_bias` podemos decirle si queremos que los atributos se combinen también con el término independiente.\n",
    "\n",
    "Vamos a ver los resultados que obtenemos, con esta **regresión polinomial**, aplicando distintos grados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una figura con 4 gráficas\n",
    "plt.figure()\n",
    "fig, sub = plt.subplots(1, 5)\n",
    "fig.set_size_inches(25, 5)\n",
    "\n",
    "grados = [1, 2, 4, 8, 12]\n",
    "for i in range(len(grados)):\n",
    "    # se definen los atributos deseados en función del grado\n",
    "    pf = PolynomialFeatures(degree=grados[i])\n",
    "\n",
    "    # se crea el pipeline con regresión lineal\n",
    "    sys_pf_linr = Pipeline([(\"pf\", pf),(\"linr\", LinearRegression())])\n",
    "\n",
    "    # se entrena con el conjunto de entrenamiento (reshape es para darle ponerlo en forma (num_ejemplos_train,1))\n",
    "    sys_pf_linr.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "    # se evalúa sobre el conjunto de test (reshape es para darle ponerlo en forma (num_ejemplos_test,1))\n",
    "    y_pred = sys_pf_linr.predict(X_test.reshape(-1,1))\n",
    "\n",
    "    # se calcula el error cuadrático medio\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # mostramos el gráfico en el subplot correspondiente\n",
    "    #plt.setp(sub[i], xticks=(), yticks=())  # quitamos los ticks\n",
    "    sub[i].plot(X_test, fun(X_test), label=\"función verdadera\")\n",
    "    sub[i].plot(X_test, y_pred, label=\"modelo\")\n",
    "    sub[i].scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"ejemplos\")\n",
    "    sub[i].set_xlabel(\"x\")\n",
    "    sub[i].set_ylabel(\"y\")\n",
    "    sub[i].set_xlim((0, 1))\n",
    "    sub[i].set_ylim((-2, 2))\n",
    "    sub[i].legend(loc=\"best\")\n",
    "    titulo = \"Grado {:d} [MSE={:0.3f}]\".format(grados[i], mse)\n",
    "    sub[i].set_title(titulo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizarlo hemos tenido que crear un `Pipeline` en el que primero se obtienen los atributos y posteriormente se calcula la regresión lineal.\n",
    "\n",
    "Hemos probado con diferentes grados y en el título de cada gráfico podemos ver el MSE obtenido en cada caso.\n",
    "\n",
    "Como vemos, a medida que aumentamos el grado corremos más riesgo de sobreajustarnos a los datos.\n",
    "\n",
    "## 23.6 Regresión con regularización\n",
    "\n",
    "En situaciones en las que queramos limitar la capacidad de sobreajuste de una regresión, podemos utilizar la regresión con regularización l2, que se implementa en el algoritmo `Ridge`: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html?highlight=ridge#sklearn.linear_model.Ridge\n",
    "\n",
    "Mediante el hiperparámetro `alpha` podemos controlar el nivel de regularización que queremos. Con valor 0 indicamos que no queremos regularización y con valores mayores vamos aumentando la regularización y por tanto reduciendo el riesgo de sobreajuste.\n",
    "\n",
    "Vamos a ver que pasa si fijamos el grado de `PolynomialFeatures` a 12, que vimos antes que se sobreajustaba mucho, y vamos aumentando el nivel de regularización aumentando poco a poco el valor de `alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### efecto de alfa en Ridge')\n",
    "print('##########################################')\n",
    "\n",
    "# creamos una figura con 4 gráficas\n",
    "plt.figure()\n",
    "fig, sub = plt.subplots(1, 5)\n",
    "fig.set_size_inches(25, 5)\n",
    "\n",
    "alfas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "for i in range(len(alfas)):\n",
    "\n",
    "    # se definen los atributos deseados en función del grado\n",
    "    pf = PolynomialFeatures(degree=12)\n",
    "\n",
    "    # se crea el pipeline con ridge\n",
    "    sys_pf_linr = Pipeline([(\"pf\", pf),(\"ridge\", Ridge(alpha=alfas[i]))])\n",
    "\n",
    "    # se entrena con el conjunto de entrenamiento (reshape es para darle ponerlo en forma (num_ejemplos,1))\n",
    "    sys_pf_linr.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "    # se evalúa sobre el conjunto de test (reshape es para darle ponerlo en forma (num_ejemplos,1))\n",
    "    y_pred = sys_pf_linr.predict(X_test.reshape(-1,1))\n",
    "\n",
    "    # se calcula el error cuadrático medio\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # mostramos el gráfico en el subplot correspondiente\n",
    "    sub[i].plot(X_test, fun(X_test), label=\"función verdadera\")\n",
    "    sub[i].plot(X_test, y_pred, label=\"modelo\")\n",
    "    sub[i].scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"ejemplos\")\n",
    "    sub[i].set_xlabel(\"x\")\n",
    "    sub[i].set_ylabel(\"y\")\n",
    "    sub[i].set_xlim((0, 1))\n",
    "    sub[i].set_ylim((-2, 2))\n",
    "    sub[i].legend(loc=\"best\")\n",
    "    titulo = \"Alfa {:.4f} [MSE={:0.3f}]\".format(alfas[i], mse)\n",
    "    sub[i].set_title(titulo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga los datos del fichero **housing.data**. \n",
    "2. Separa el conjunto de datos para hacer un hold out 80-20.\n",
    "3. Evalúa los siguientes sistemas (con sus hiperparámetros por defecto) sobre esa partición: sistema media, regresión lineal (con y sin regularización) y regresión polinomial (con y sin regularización).\n",
    "4. Muestra, en forma de tabla, los resultados de las tres métricas explicadas en el notebook.\n",
    "5. Finalmente, calcula el error cuadrático medio que obtiene una regresión polinomial en una validación cruzada de 5 folds.\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
