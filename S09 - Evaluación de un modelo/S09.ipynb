{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 09 - Evaluación del rendimiento de un modelo\n",
    "\n",
    "Cuando queremos evaluar un modelo, lo primero que se nos viene a la cabeza es entrenar el modelo utilizando unos datos y luego utilizar una métrica (accuracy por ejemplo) para medir el rendimiento de ese modelo sobre los mismos datos que se han utilizado para entrenar. Sin embargo, esto es un error puesto que estaremos obteniendo resultados que sobreestiman el verdadero rendimiento del modelo.\n",
    "\n",
    "**Una correcta evaluación de un modelo es aquella que utiliza datos distintos a los utilizado durante el entrenamiento.**\n",
    "\n",
    "En esta práctica vamos a ver cómo podemos hacer evaluaciones de modelos de manera correcta.\n",
    "\n",
    "## 9.1 Reescritura (Resubstitution)\n",
    "\n",
    "Si utilizamos todos los datos de que disponemos para entrenar el modelo y, posteriormente, utilizamos esos mismos datos para evaluar el modelo estaremos haciendo lo que se conoce como reescritura o resubstitution.\n",
    "\n",
    "Veamos con un ejemplo cuál es el problema de esta técnica de evaluación. Para ello vamos a cargar el conjunto 'ionosphere.data' transformando la clase a valores numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atr1</th>\n",
       "      <th>atr2</th>\n",
       "      <th>atr3</th>\n",
       "      <th>atr4</th>\n",
       "      <th>atr5</th>\n",
       "      <th>atr6</th>\n",
       "      <th>atr7</th>\n",
       "      <th>atr8</th>\n",
       "      <th>atr9</th>\n",
       "      <th>atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>atr25</th>\n",
       "      <th>atr26</th>\n",
       "      <th>atr27</th>\n",
       "      <th>atr28</th>\n",
       "      <th>atr29</th>\n",
       "      <th>atr30</th>\n",
       "      <th>atr31</th>\n",
       "      <th>atr32</th>\n",
       "      <th>atr33</th>\n",
       "      <th>atr34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95378</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94520</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93988</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91050</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86467</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atr1  atr2     atr3     atr4     atr5     atr6     atr7     atr8  \\\n",
       "0       1     0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708   \n",
       "1       1     0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597   \n",
       "2       1     0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062   \n",
       "3       1     0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000   \n",
       "4       1     0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255   \n",
       "..    ...   ...      ...      ...      ...      ...      ...      ...   \n",
       "346     1     0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567   \n",
       "347     1     0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920   \n",
       "348     1     0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431   \n",
       "349     1     0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646   \n",
       "350     1     0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260   \n",
       "\n",
       "        atr9    atr10  ...    atr25    atr26    atr27    atr28    atr29  \\\n",
       "0    1.00000  0.03760  ...  0.56811 -0.51171  0.41078 -0.46168  0.21266   \n",
       "1    1.00000 -0.04549  ... -0.20332 -0.26569 -0.20468 -0.18401 -0.19040   \n",
       "2    0.88965  0.01198  ...  0.57528 -0.40220  0.58984 -0.22145  0.43100   \n",
       "3    0.00000  0.00000  ...  1.00000  0.90695  0.51613  1.00000  1.00000   \n",
       "4    0.77152 -0.16399  ...  0.03286 -0.65158  0.13290 -0.53206  0.02431   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "346  0.90441 -0.04622  ...  0.95378 -0.04202  0.83479  0.00123  1.00000   \n",
       "347  0.94590  0.01606  ...  0.94520  0.01361  0.93522  0.04925  0.93159   \n",
       "348  0.95584  0.02446  ...  0.93988  0.03193  0.92489  0.02542  0.92120   \n",
       "349  0.85746  0.00110  ...  0.91050 -0.02099  0.89147 -0.07760  0.82983   \n",
       "350  0.88928 -0.09139  ...  0.86467 -0.15114  0.81147 -0.04822  0.78207   \n",
       "\n",
       "       atr30    atr31    atr32    atr33    atr34  \n",
       "0   -0.34090  0.42267 -0.54487  0.18641 -0.45300  \n",
       "1   -0.11593 -0.16626 -0.06288 -0.13738 -0.02447  \n",
       "2   -0.17365  0.60436 -0.24180  0.56045 -0.38238  \n",
       "3   -0.20099  0.25682  1.00000 -0.32382  1.00000  \n",
       "4   -0.62197 -0.05707 -0.59573 -0.04608 -0.65697  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "346  0.12815  0.86660 -0.10714  0.90546 -0.04307  \n",
       "347  0.08168  0.94066 -0.00035  0.91483  0.04712  \n",
       "348  0.02242  0.92459  0.00442  0.92697 -0.00577  \n",
       "349 -0.17238  0.96022 -0.03757  0.87403 -0.16243  \n",
       "350 -0.00703  0.75747 -0.06678  0.85764 -0.06151  \n",
       "\n",
       "[351 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "346    1\n",
       "347    1\n",
       "348    1\n",
       "349    1\n",
       "350    1\n",
       "Name: clase, Length: 351, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se importan las librerías\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "\n",
    "# se llama a la función read_csv\n",
    "# no tiene missing y las columnas están separadas por ','\n",
    "# tampoco cabecera, así que hay que dar nombre a las columnas (como en el names no vienen indicados creamos nombres)\n",
    "cabecera = ['atr'+str(x) for x in range(1,35)] # for en línea para crear elementos de una lista\n",
    "cabecera.append('clase') # la clase está en la última posición\n",
    "\n",
    "df = pd.read_csv('ionosphere.data', names=cabecera)\n",
    "filas, columnas = df.shape\n",
    "\n",
    "# la clase está en la última columna \n",
    "# separamos los atributos y los almacenamos en X\n",
    "X = df.drop(['clase'], axis=1)\n",
    "display(X)\n",
    "\n",
    "# transformamos la clase\n",
    "class_enc = preprocessing.LabelEncoder()\n",
    "df['clase'] = class_enc.fit_transform(df['clase'])\n",
    "\n",
    "# separamos la clase y la almacenamos en Y\n",
    "y = df['clase']\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver la accuracy que obtiene el sistema que predice siempre la clase mayoritaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Resultados para DummyClassifier con strategy='most_frequent' ###\n",
      "Accuracy : 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "# creamos el sistema DummyClassifier strategy=\"most_frequent\"\n",
    "cl_my_sis = DummyClassifier(strategy=\"most_frequent\")\n",
    "cl_my_sis.fit(X, y)\n",
    "y_pred = cl_my_sis.predict(X)\n",
    "print(\"\\n### Resultados para DummyClassifier con strategy='most_frequent' ###\")\n",
    "print(\"Accuracy :\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la accuracy obtenida por un `KNN` con `n_neighbors=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Resultados para KNeighborsClassifier con n_neighbors=1 ###\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# creamos una instancia del KNN\n",
    "knn_sis = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_sis.fit(X, y)\n",
    "y_pred = knn_sis.predict(X)\n",
    "print(\"\\n### Resultados para KNeighborsClassifier con n_neighbors=1 ###\")\n",
    "print(\"Accuracy :\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que este último sistema tiene un porcentaje de acierto del 100%.\n",
    "\n",
    "¿Quiere esto decir que hemos entrenado un modelo que es perfecto a la hora de predecir? NO, lo que quiere decir es que la reescritura no es un buen modelo para medir la calidad de nuestro modelo en el futuro.\n",
    "\n",
    "Si queremos tener una estimación de la calidad de nuestro modelo cuando esté *en producción*, entonces debemos comprobar su rendimiento con casos que no haya visto durante el entrenamiento. Hay varias formas de simular esta situación:\n",
    "1. Hold-out (entrenamiento-test, validation)\n",
    "2. Validación cruzada (cross validation)\n",
    "3. Leave-one-out\n",
    "\n",
    "## 9.2 Hold-out (entrenamiento-test)\n",
    "\n",
    "La manera más sencilla de lograr lo que pretendemos es simplemente partir el conjunto de datos (data set) en dos trozos que tradicionalmente se llaman *training set* y *test set* (a veces también *validation set*). \n",
    "\n",
    "![Hold-out](fig_holdout.png) \n",
    "\n",
    "A esta técnica se la conoce como **Hold-out** (a veces también entrenamiento-test) y normalmente se suelen reservar más ejemplos para el entrenamiento que para el test. Una división típica puede ser 75%-25% aunque dependerá de las particularidades de cada conjunto.\n",
    "\n",
    "Veamos cómo implementar un hold-out utilizando la función `train_test_split()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy clase mayoritaria: 0.6023\n",
      "Accuracy KNN con 1 vecino : 0.8182\n"
     ]
    }
   ],
   "source": [
    "# se separan train y test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# reentrenamos el baseline\n",
    "cl_my_sis.fit(X_train, y_train)     # se entrena sobre la partición de train\n",
    "y_test_pred = cl_my_sis.predict(X_test)  # se predice sobre la partición de test\n",
    "print(\"Accuracy clase mayoritaria: %.4f\" % accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# reentrenamos el vecino más próximo\n",
    "knn_sis.fit(X_train, y_train)       # se entrena sobre la partición de train\n",
    "y_test_pred = knn_sis.predict(X_test)    # se predice sobre la partición de test\n",
    "print(\"Accuracy KNN con 1 vecino : %.4f\" % accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el KNN ya no tiene un acierto del 100% sino que baja a un 85% aproximadamente. Como se está haciendo el test sobre ejemplos que no ha visto en el entrenamiento el modelo debe enfrentarse a casos desconocidos y su resultado ya no es tan bueno, pero ahora sí que estamos generando una situación más parecida a la que tendría el sistema en producción.\n",
    "\n",
    "Hay varios detalles interesantes en el código anterior:\n",
    "1. `train_test_split()` retorna 2 elementos por cada elemento que le damos a partir. Como en este caso le damos para dividir `X` e `y` nos devolverá 4 elementos.\n",
    "2. Podemos indicarle cómo queremos hacer la división utilizando los parámetros `test_size` o `train_size`. \n",
    "3. El entrenamiento **debe** hacerse utilizando el train set\n",
    "4. La predicción **debe** hacerse utilizando el test set\n",
    "\n",
    "En https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html se pueden ver todos los parámetros que tiene la función.\n",
    "\n",
    "### 9.2.1 Barajado y estratificado\n",
    "\n",
    "Si ejecutas varias veces el código anterior verás que cada vez obtendrás resultados diferentes. Esto es así porque antes de hacer la partición, la función `train_test_split()` realiza un barajado de los ejemplos basándose en un generador de números pseudoaleatorios. Como nos interesa que los resultados puedan reproducirse, normalmente incilializaremos el estado del generador de números pseudoaleatorios utilizando el parámetro `random_state`. \n",
    "\n",
    "Además, como las particiones se realizan de manera aleatoria, podría darse el caso de que todos los ejemplos de una clase quedasen en el train set y los de la otra clase en el test set y eso dificultaría el aprendizaje del modelo. Para evitar este tipo de situaciones, se suele realizar una partición **estratificada** que tratará de mantener en los conjuntos de entrenamiento y test la misma proporción de ejemplos de cada clase que se tenía en el conjunto de datos original (completo). Para lograr esto utilizaremos el parámetro `stratify` al que le asignaremos el vector que utilizará de guía para realizar la estratificación.\n",
    "\n",
    "Esta sería una mejor implementación y aunque la ejecutemos varias veces, siempre obtendremos el mismo resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy clase mayoritaria: 0.6364\n",
      "Accuracy KNN con 1 vecino : 0.8864\n"
     ]
    }
   ],
   "source": [
    "# se separan train y test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234, stratify=y)\n",
    "\n",
    "# reentrenamos el baseline\n",
    "cl_my_sis.fit(X_train, y_train)     # se entrena sobre la partición de train\n",
    "y_test_pred = cl_my_sis.predict(X_test)  # se predice sobre la partición de test\n",
    "print(\"Accuracy clase mayoritaria: %.4f\" % accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# reentrenamos el vecino más próximo\n",
    "knn_sis.fit(X_train, y_train)       # se entrena sobre la partición de train\n",
    "y_test_pred = knn_sis.predict(X_test)    # se predice sobre la partición de test\n",
    "print(\"Accuracy KNN con 1 vecino : %.4f\" % accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.2 Problemas del Hold-out\n",
    "\n",
    "El primer problema es que el resultado será muy dependiente de los pocos ejemplos que hemos separado como conjunto de test. ¿Qué pasaría si por azar los ejemplos más fáciles o difíciles de clasificar quedasen todos en el conjunto de test?, pues que el rendimiento obtenido no reflejaría el verdadero rendimiento que el modelo tendría en producción. Esto se podría solucionar dejando más ejemplos para el conjunto de test, pero eso agravaría el segundo problema.\n",
    "\n",
    "El segundo problema es que no estamos utilizando todos los ejemplos disponibles para entrenar bien al modelo. Estamos reservando unos ejemplos para la evaluación y al no utilizarlos estamos perdiendo conocimiento. Este problema se podría solucionar utilizando más ejemplos para el entrenamiento, pero eso agravaría el primer problema.\n",
    "\n",
    "Como vemos, esta técnica presenta dos problemas que no puede solucionar a la vez.\n",
    "\n",
    "## 9.3 Cross validation (Validación cruzada)\n",
    "\n",
    "Para solucionar los problemas que presenta el Hold-out existe otra técnica de evaluación del rendimiento de un modelo que se conoce como **cross validation** o validación cruzada.\n",
    "\n",
    "Esta técnica consiste en dividir el conjunto de datos en K *folds* y realizar K hold-out dejando en cada iteración un fold diferente como conjunto de test. Esta manera de evaluar un modelo se llama **K-Fold Cross Validation** (KFCV):\n",
    "\n",
    "![Cross validation](fig_cv.png) \n",
    "\n",
    "Como vemos en la figura, tendremos K resultados que se combinarán utilizando la media para obtener la estimación de rendimiento del sistema.\n",
    "\n",
    "Utilizando una KFCV se soluciona el primero de los problemas que observamos en el hold-out y se suaviza el segundo: \n",
    "- Todos los ejemplos forman parte del conjunto de test en alguna iteración. Así ya no tendremos el problema que veíamos en el hold-out.\n",
    "- La mayoría de los ejemplos se utilizan en el entrenamiento. Pero no todos, los modelos que se entrenan en la KFCV siguen sin utilizar todos los ejemplos para entrenar los modelos. Cuanto mayor sea el valor de la K, más se suavizará este problema.\n",
    "\n",
    "Valores típicos para el número de folds son 5 y 10.\n",
    "\n",
    "Vamos a ver cómo podemos implementarlo utilizando la función `cross_val_score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase mayoritaria: [0.63380282 0.64285714 0.64285714 0.64285714 0.64285714]\n",
      "KNN con 1 vecino : [0.87323944 0.82857143 0.85714286 0.87142857 0.88571429]\n",
      "\n",
      "Tiempo del KNN: 0.05 segundos\n",
      "\n",
      "Clase mayoritaria (mean+-std): 0.6410 +- 0.0036\n",
      "KNN con 1 vecino  (mean+-std): 0.8632 +- 0.0196\n"
     ]
    }
   ],
   "source": [
    "# se crea un generador de folds estratificados partiendo el conjunto en 5 trozos\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# se realiza la validación cruzada para el baseline\n",
    "scores_cl_may = cross_val_score(cl_my_sis, X, y, cv=folds, scoring='accuracy')\n",
    "print(\"Clase mayoritaria:\", scores_cl_may)\n",
    "\n",
    "# se toman tiempos de ejecución para la validación cruzada del KNN\n",
    "ini = time.time()\n",
    "scores_knn = cross_val_score(knn_sis, X, y, cv=folds, scoring='accuracy')\n",
    "fin = time.time()\n",
    "print(\"KNN con 1 vecino :\", scores_knn)\n",
    "print(\"\\nTiempo del KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "print(\"\\nClase mayoritaria (mean+-std): %0.4f +- %0.4f\" % (scores_cl_may.mean(), scores_cl_may.std()))\n",
    "print(\"KNN con 1 vecino  (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, a `cross_val_score()` tenemos que pasarle el sistema, la matriz de atributos, la clase, los folds que queremos utilizar y la métrica para la que queremos obtener el resultado. En https://scikit-learn.org/stable/modules/model_evaluation.html podemos ver el nombre de las métricas y las funciones asociadas.\n",
    "\n",
    "En el parámetro `cv` de la función le estamos pasando un `StratifiedKFold`, que va a permitir generar folds partiendo el conjunto de datos en `n_splits` trozos, barajando previamente los ejemplos. Además, fijamos la semilla de números aleatorios para que el experimento sea reproducible.\n",
    "Podríamos haber indicado directamente `cv=5` en la función `cross_val_score()` y también generaría los folds utilizando `StratifiedKFold` cuando estamos con conjuntos de datos de clasificación, sin embargo, **no barajaría los ejemplos**. Barajar los ejemplos es importante para evitar sesgos, con lo que recomendamos barajar los ejemplos por nuestra cuenta antes de llamar a `cross_val_score()` o utilizar `StratifiedKFold` con `shuffle=True`:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "\n",
    "Si os fijáis hemos tomado tiempos para saber cuánto tarda en ejecutarse puesto que vamos a comparar tiempos más adelante.\n",
    "\n",
    "`cross_val_score()` es la manera más sencilla de hacer una KFCV en `scikit-learn`, pero hay otras formas más versátiles. Por ejemplo, utilizando `cross_validate()` podríamos obtener el resultado de varias métricas simultáneamente y además obtendríamos un desglose de tiempos (entrenamiento y predicción): https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate Pero en esta asignatura vamos a centrarnos en el uso básico de `cross_val_score()`.\n",
    "\n",
    "Vamos a ver ahora qué resultados se obtienen con K=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase mayoritaria: [0.63888889 0.65714286 0.65714286 0.65714286 0.65714286 0.62857143\n",
      " 0.62857143 0.62857143 0.62857143 0.62857143]\n",
      "KNN con 1 vecino : [0.83333333 0.94285714 0.91428571 0.85714286 0.88571429 0.82857143\n",
      " 0.8        0.91428571 0.88571429 0.91428571]\n",
      "\n",
      "Tiempo del KNN: 0.08 segundos\n",
      "\n",
      "Clase mayoritaria (mean+-std): 0.6410 +- 0.0135\n",
      "KNN con 1 vecino  (mean+-std): 0.8776 +- 0.0439\n"
     ]
    }
   ],
   "source": [
    "# se crea un generador de folds estratificados partiendo el conjunto en 10 trozos\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "# se realiza la validación cruzada para el baseline\n",
    "scores_cl_may = cross_val_score(cl_my_sis, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Clase mayoritaria:\", scores_cl_may)\n",
    "\n",
    "# se toman tiempos de ejecución para la validación cruzada del KNN\n",
    "ini = time.time()\n",
    "scores_knn = cross_val_score(knn_sis, X, y, cv=folds, scoring='accuracy')\n",
    "fin = time.time()\n",
    "print(\"KNN con 1 vecino :\", scores_knn)\n",
    "print(\"\\nTiempo del KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "print(\"\\nClase mayoritaria (mean+-std): %0.4f +- %0.4f\" % (scores_cl_may.mean(), scores_cl_may.std()))\n",
    "print(\"KNN con 1 vecino  (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados son bastante similares y que el tiempo de ejecución se ha incrementado.\n",
    "\n",
    "## 9.4 Leave-one-out\n",
    "\n",
    "Y así es como llegamos a la mejor estimación que podemos conseguir, que es utilizando la técnica que se conoce como **leave-one-out** y que no es más que una K-Fold Cross Validation en la que la K es igual al número de ejemplos.\n",
    "\n",
    "De esta manera se realizarán tantos entrenamientos como número de ejemplos tenga el conjunto de datos, dejando en cada iteración un solo ejemplo para el conjunto de test. Esto es lo más parecido que podemos tener a un sistema en producción puesto que se utilizan todos los ejemplos menos uno para entrenar el modelo. Además, todos los ejemplos estarán una vez en el conjunto de test, con lo que la media del rendimiento que tengamos al final incluirá a todos los ejemplos, ya sean fáciles o difíciles. \n",
    "\n",
    "**Problema:** Se realizarán tantos entrenamientos como número de ejemplos tengamos en el conjunto y esto hace que la mayoría de las veces el leave-one-out sea impracticable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase mayoritaria: [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "KNN con 1 vecino : [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Tiempo del KNN: 1.86 segundos\n",
      "\n",
      "Clase mayoritaria (mean+-std): 0.6410 +- 0.4797\n",
      "KNN con 1 vecino  (mean+-std): 0.8661 +- 0.3405\n"
     ]
    }
   ],
   "source": [
    "# se realiza el leave-one-out para el baseline\n",
    "scores_cl_may = cross_val_score(cl_my_sis, X, y, cv=LeaveOneOut(), scoring='accuracy')\n",
    "print(\"Clase mayoritaria:\", scores_cl_may)\n",
    "\n",
    "# se toman tiempos de ejecución para el leave-one-out del KNN\n",
    "ini = time.time()\n",
    "scores_knn = cross_val_score(knn_sis, X, y, cv=LeaveOneOut(), scoring='accuracy')\n",
    "fin = time.time()\n",
    "print(\"KNN con 1 vecino :\", scores_knn)\n",
    "print(\"\\nTiempo del KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "print(\"\\nClase mayoritaria (mean+-std): %0.4f +- %0.4f\" % (scores_cl_may.mean(), scores_cl_may.std()))\n",
    "print(\"KNN con 1 vecino  (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos resaltar varias cosas en el resultado obtenido:\n",
    "1. El leave-one-out necesita mucho más tiempo de ejecución.\n",
    "2. El resultado mejora puesto que estamos utilizando más ejemplos para entrenar los modelos. Esto no siempre será así, pero si nuestro sistema es bueno y le damos más ejemplos para entrenar, debería sacar provecho de esos datos y generar un modelo mejor.\n",
    "3. El resultado de cada fold es 1 o 0 puesto que al haber un solo ejemplo en el test o se acierta o se falla (en los problemas de clasificación).\n",
    "\n",
    "En cuanto a la implementación, vemos que para ejecutar un leave-one-out únicamente tenemos que utilizar la función `cross_val_score()` indicando en el parámetro `cv` lo siguiente: `cv=LeaveOneOut()`. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html \n",
    "\n",
    "### 9.4.1 Paralelizar ejecuciones\n",
    "\n",
    "Muchos sistemas y muchas funciones de `scikit-learn` nos dan la posibilidad de paralelizar y sacar el máximo provecho a nuestras CPUs. Lo hacen a través del parámetro `n_jobs` en el que podemos indicarle el número de CPUs que queremos utilizar. Si queremos utilizar todas las CPUs entonces debemos poner `n_jobs=-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con 1 vecino : [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Tiempo del KNN: 0.54 segundos\n",
      "KNN con 1 vecino  (mean+-std): 0.8661 +- 0.3405\n"
     ]
    }
   ],
   "source": [
    "# se toman tiempos de ejecución para el leave-one-out del KNN\n",
    "ini = time.time()\n",
    "scores_knn = cross_val_score(knn_sis, X, y, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1)\n",
    "fin = time.time()\n",
    "print(\"KNN con 1 vecino :\", scores_knn)\n",
    "print(\"\\nTiempo del KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "print(\"KNN con 1 vecino  (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera vez que lo ejecutes igual tarda un poco más por cuestiones de inicializaciones, pero si vuelves a repetir la ejecución verás que el tiempo se reduce considerablemente.\n",
    "\n",
    "## 9.5 Cómo preprocesar los datos cuando tenemos un conjunto de test (MUY IMPORTANTE)\n",
    "\n",
    "En los métodos de evaluación que hemos comentado, los modelos siempre se entrenan con unos ejemplos determinados (train set) y se evalúa su rendimiento con otros ejemplos que no se ven durante el entrenamiento (test set). \n",
    "\n",
    "Actuamos de esta manera porque queremos simular una situación real en la que se entrena el modelo con todos los ejemplos disponibles hasta un instante determinado y a partir de ese momento comienza a realizar predicciones para los ejemplos que comienzan a llegar a partir de ese instante.\n",
    "\n",
    "Por tanto, si nuestro sistema requiere realizar algún preprocesado de los datos, los parámetros del preprocesado se deben ajustar sobre los ejemplos del conjunto de entrenamiento únicamente. Si incluyésemos los del conjunto de test estaríamos utilizando datos que supuestamente no podríamos estar viendo.\n",
    "\n",
    "### 9.5.1 Preprocesado y hold-out\n",
    "Veamos cómo se haría un hold-out con preprocesado y para ello vamos a utilizar un conjunto que ya habíamos visto en la práctica anterior que tenía los atributos con órdenes de magnitud diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy clase mayoritaria: 0.36\n",
      "Accuracy KNN con 1 vecino : 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('ejemplo.xlsx', sheet_name='datos')\n",
    "filas, columnas = df.shape\n",
    "\n",
    "# separamos las primeras columnas y las almacenamos en X\n",
    "X = df.iloc[:,0:(columnas-1)]\n",
    "\n",
    "# separamos la clase\n",
    "y = df.iloc[:,(columnas-1)]\n",
    "\n",
    "# realizamos la partición\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234, test_size=0.25)\n",
    "\n",
    "# creamos el StandardScaler\n",
    "std_sca = preprocessing.StandardScaler()\n",
    "\n",
    "# se entrena el StandardScaler SOLO con el conjunto de entrenamiento\n",
    "std_sca.fit(X_train)\n",
    "\n",
    "# se transforma el conjunto de entrenamiento y el de test\n",
    "X_train_std = std_sca.transform(X_train)\n",
    "X_test_std = std_sca.transform(X_test)\n",
    "\n",
    "# calculamos la accuracy del baseline para tener una referencia\n",
    "cl_my_sis.fit(X_train_std, y_train)\n",
    "y_pred = cl_my_sis.predict(X_test_std)\n",
    "print(\"Accuracy clase mayoritaria:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# calculamos la accuracy del KNN\n",
    "knn_sis.fit(X_train_std, y_train)    # se utilizan los atributos ya escalados\n",
    "y_pred = knn_sis.predict(X_test_std) # se utilizan los atributos ya escalados\n",
    "print(\"Accuracy KNN con 1 vecino :\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el `StandardScaler` utiliza únicamente los ejemplos del conjunto de entrenamiento para calcular la media y la desviación que necesita para escalar los datos. Una vez calculada la media y la desviación debemos utilizar `transform` para escalar el conjunto de entrenamiento y el de test.\n",
    "\n",
    "Esos conjuntos transformados serán los que utilizaremos para entrenar el modelo y realizar las predicciones. Aquí debemos ser cuidadosos, ya que si entrenamos con `X_train_std` y predecimos para los casos contenidos en `X_test` (nos hemos olvidado de escalarlos) los resultados que obtendremos serán muy malos. Puedes probar.\n",
    "\n",
    "### 9.5.2 Preprocesado y validación cruzada o leave-one-out\n",
    "\n",
    "Si en lugar de un hold-out queremos realizar una validación cruzada o un leave-one-out, entonces debemos crear un `Pipeline` y utilizarlo como un sistema más. No hay que hacer nada especial.\n",
    "\n",
    "Vamos a ver cómo se hace una validación cruzada sin estandarizar y estandarizando para que veamos que la única diferencia es que hay que crear el `Pipeline`:\n",
    "\n",
    "(en este ejemplo ponemos directamente el número del folds que queremos utilizar, pero ya comentamos más arriba que esto puede resultar peligroso puesto que, aunque se llama por defecto a `StratifiedKFold`, no se barajarían los ejemplos antes de separarlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se realiza la validación cruzada para el baseline\n",
    "scores_cl_may = cross_val_score(cl_my_sis, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# se toman tiempos de ejecución para la validación cruzada del KNN (sin estandarizar)\n",
    "ini = time.time()\n",
    "scores_knn = cross_val_score(knn_sis, X, y, cv=10, scoring='accuracy')\n",
    "fin = time.time()\n",
    "print(\"Tiempo del KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "# se crea un Pipeline que estandariza y usa un KNN\n",
    "std_knn = Pipeline([('std', std_sca), ('knn', knn_sis)])\n",
    "\n",
    "# se toman tiempos de ejecución para la validación cruzada del KNN (estandarizando)\n",
    "ini = time.time()\n",
    "scores_std_knn = cross_val_score(std_knn, X, y, cv=10, scoring='accuracy')\n",
    "fin = time.time()\n",
    "print(\"Tiempo del STD_KNN: %.2f segundos\" % (fin-ini))\n",
    "\n",
    "print(\"\\nClase mayoritaria     (mean+-std): %0.4f +- %0.4f\" % (scores_cl_may.mean(), scores_cl_may.std()))\n",
    "print(\"KNN con 1 vecino      (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))\n",
    "print(\"STD_KNN con 1 vecino  (mean+-std): %0.4f +- %0.4f\" % (scores_std_knn.mean(), scores_std_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso ya se encarga `cross_val_score()` de entrenar los modelos con los conjuntos adecuados y de realizar las predicciones sobre los conjuntos ya estandarizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga el fichero **heart_failure_clinical_records_dataset.csv** (es un archivo de texto). \n",
    "2. Crea el baseline de la clase mayoritaria y un KNN con 3 vecinos\n",
    "3. Haz un hold-out con una partición 75%-25% (ten en cuenta que los atributos tienen escalas diferentes).\n",
    "4. Haz una validación cruzada de 10 folds.\n",
    "5. Haz un leave-one-out.\n",
    "6. Haz una gráfica en la que se vea la evolución (en función del número de vecinos [1..10]) de la accuracy obtenida en una validación cruzada de 10 folds estandarizando y sin estandarizar.\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
