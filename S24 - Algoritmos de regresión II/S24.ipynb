{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 24 - Otros algoritmos de regresión\n",
    "\n",
    "En las sesiones anteriores hemos explicado las ideas fundamentales de varios algoritmos de aprendizaje automático. \n",
    "Muchos de esos algoritmos pueden utilizarse también en tareas de regresión.\n",
    "\n",
    "En esta sesión vamos a ir comentando las particularidades de cada uno de esos algoritmos para poder resolver tareas de regresión.\n",
    "\n",
    "Vamos a cargar un conjunto de datos para poder ejecutar algún algoritmo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################\n",
      "### cargar el conjunto y separar X e y\n",
      "##########################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Name: MEDV, Length: 506, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################\n",
      "### Hold-out 80-20\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### cargar el conjunto y separar X e y')\n",
    "print('##########################################')\n",
    "\n",
    "# se llama a la función read_csv\n",
    "# no tiene missing y las columnas están separadas por uno o varios espacios en blanco '\\s+'. No tiene cabecera\n",
    "cabecera = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df = pd.read_csv('housing.data', sep='\\s+', names=cabecera)\n",
    "filas, columnas = df.shape\n",
    "\n",
    "\n",
    "# la clase está en la última columna \n",
    "# separamos los atributos y los almacenamos en X\n",
    "X = df.drop(['MEDV'], axis=1)\n",
    "display(X)\n",
    "\n",
    "# separamos la clase y la almacenamos en Y\n",
    "y = df['MEDV']\n",
    "display(y)\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Hold-out 80-20')\n",
    "print('##########################################')\n",
    "\n",
    "# en los problemas de regresión no tiene sentido estratificar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 24.1 K-vecinos\n",
    "\n",
    "La esencia de este algoritmo es localizar los `n_neighbors` vecinos más cercanos y realizar una predicción condicionada por los valores que tienen esos vecinos:\n",
    "- si `weights=uniform` la predicción será la media de la clase de los vecinos más próximos\n",
    "- si `weights=distance` la predicción será la media ponderada por la distancia a la que está cada vecino\n",
    "\n",
    "En `Scikit-learn` contamos con `KNeighborsRegressor` para aplicar este algoritmos en problemas de regresión. En https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html?highlight=regressor#sklearn.neighbors.KNeighborsRegressor podéis ver más detalles.\n",
    "\n",
    "Veamos un ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 4.713\n",
      "MSE = 45.424\n",
      "R2 = 0.557\n"
     ]
    }
   ],
   "source": [
    "# se crea el k-vecinos\n",
    "sys = KNeighborsRegressor()\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.2 Árboles de decisión \n",
    "\n",
    "Ya vimos que una de las cualidades de los árboles de decisión es su capacidad explicativa y por eso siguen siendo tan utilizados.\n",
    "\n",
    "Los árboles de decisión en tareas de regresión, para decidir cual es el mejor punto de corte para utilizar un atributo como nodo en el árbol, **escogen aquel que minimiza el error cuadrático medio**.\n",
    "\n",
    "Para trabajar con problemas de regresión contamos con `DecisionTreeRegressor` que comparte muchas de las características que ya vimos en el clasificador:\n",
    "- `max_depth`, profundidad máxima del árbol.\n",
    "- `min_samples_split`, mínimo número de ejemplos que debe tener un nodo para ser dividido.\n",
    "- `min_samples_leaf`, mínimo número de ejemplos requeridos en una hoja.\n",
    "- `max_leaf_nodes`, máximo número de hojas.\n",
    "- `min_impurity_decrease`, mímino decrecimiento requerido de la impureza para aceptar una división.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html?highlight=decisiontree#sklearn.tree.DecisionTreeRegressor\n",
    "\n",
    "Vamos a ejecutarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.612\n",
      "MSE = 12.366\n",
      "R2 = 0.880\n"
     ]
    }
   ],
   "source": [
    "# se crea el árbol de decisión\n",
    "sys = DecisionTreeRegressor(random_state=1234)\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a visualizar el árbol generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\UO281798\\Documents\\GitHub\\AprendizajeAutomaticoPL\\S24 - Algoritmos de regresión II\\S24.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UO281798/Documents/GitHub/AprendizajeAutomaticoPL/S24%20-%20Algoritmos%20de%20regresi%C3%B3n%20II/S24.ipynb#ch0000007?line=6'>7</a>\u001b[0m graph \u001b[39m=\u001b[39m pydotplus\u001b[39m.\u001b[39mgraph_from_dot_data(dot_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UO281798/Documents/GitHub/AprendizajeAutomaticoPL/S24%20-%20Algoritmos%20de%20regresi%C3%B3n%20II/S24.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39m# lo visualizamos\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/UO281798/Documents/GitHub/AprendizajeAutomaticoPL/S24%20-%20Algoritmos%20de%20regresi%C3%B3n%20II/S24.ipynb#ch0000007?line=9'>10</a>\u001b[0m Image(graph\u001b[39m.\u001b[39;49mcreate_png())\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pydotplus\\graphviz.py:1797\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1791'>1792</a>\u001b[0m \u001b[39m# Automatically creates all the methods enabling the creation\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1792'>1793</a>\u001b[0m \u001b[39m# of output in any of the supported formats.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1793'>1794</a>\u001b[0m \u001b[39mfor\u001b[39;00m frmt \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformats:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1794'>1795</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1795'>1796</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcreate_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m frmt,\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1796'>1797</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m f\u001b[39m=\u001b[39mfrmt, prog\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mf, prog\u001b[39m=\u001b[39;49mprog)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1797'>1798</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1798'>1799</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcreate_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m frmt]\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1799'>1800</a>\u001b[0m     f\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m (\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1800'>1801</a>\u001b[0m         \u001b[39m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1801'>1802</a>\u001b[0m         \u001b[39m''''create' method for more information.'''\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1802'>1803</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pydotplus\\graphviz.py:1959\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1956'>1957</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogs \u001b[39m=\u001b[39m find_graphviz()\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1957'>1958</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1958'>1959</a>\u001b[0m         \u001b[39mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1959'>1960</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mGraphViz\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms executables not found\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1961'>1962</a>\u001b[0m \u001b[39mif\u001b[39;00m prog \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogs:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1962'>1963</a>\u001b[0m     \u001b[39mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pydotplus/graphviz.py?line=1963'>1964</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mGraphViz\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms executable \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m prog)\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# se obtiene la representación en formato 'dot' del árbol de decisión\n",
    "dot_data = export_graphviz(decision_tree=sys, feature_names=X.columns, filled=True)\n",
    "#print(\"Si no tienes GraphViz instalado, para visualizar el árbol copia y pega lo siguiente en: https://dreampuf.github.io/GraphvizOnline/\")\n",
    "#print(dot_data)\n",
    "\n",
    "# se transforma la representación de árbol en formato 'dot' a formato gráfico\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# lo visualizamos\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol generado es inmenso. Puedes probar a limitarlo de alguna manera.\n",
    "\n",
    "## 24.3 Máquinas de vectores soporte\n",
    "\n",
    "Las Máquinas de Vectores Soporte (SVM) para regresión siguen una filosofía similar a las de clasificación.\n",
    "\n",
    "Los problemas de regresión son un poco más complicados puesto que acertar exactamente un valor continuo es casi imposible. Por esta razón se incorpora un nuevo hiperparámetro la ecuación, $\\epsilon$ (`epsilon`), que servirá para indicar la tolerancia que tendremos respecto a los fallos. Si el valor predicho para un ejemplo $x_i$ es $\\hat{y}_i$:\n",
    "- se considerará que el error cometido es 0 si $(y_i-\\epsilon) \\le \\hat{y}_i \\le (y_i+\\epsilon)$\n",
    "- en cualquier otro caso, el error será la diferencia con el borde más cercano\n",
    "\n",
    "De esta forma se calculan los errores que comete el sistema, que tendrán mayor o menor importancia durante el aprendizaje en función del hiperparámtero `C`, que ya habíamos visto que actúa como equilibrio entre el sumatorio de los errores y la norma de $w$, los parámetros que se aprenden.\n",
    "\n",
    "En `sklearn` disponemos de `SVR` como implementación de las SVM de regresión. Esta implementación cuenta también con la posibilidad de utilizar diferentes kernels, siendo los más utilizados `'linear'`, `'poly'` (al que debemos indicarle el `degree`) y `'rbf'` (que se verá afectado por la `gamma` indicada).\n",
    "\n",
    "Podéis encontrar más información en: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "\n",
    "Veamos un ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.650\n",
      "MSE = 16.298\n",
      "R2 = 0.841\n"
     ]
    }
   ],
   "source": [
    "# se crea una SVM\n",
    "sys = SVR(kernel='rbf', epsilon=0.01, C=100000)\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes probar diferentes kernels e hiperparámetros para ver cómo afecta al rendimiento del modelo.\n",
    "\n",
    "## 24.4 Bagging\n",
    "\n",
    "Ya habíamos comentado en su momento que la idea detrás del bagging es muy sencilla: se entrenarán muchos modelos utilizando particiones del conjunto de datos ligeramente diferentes y se combinarán las salidas de todos ellos para obtener la predicción final. Al tener muchos modelos, unos se sobreajustarán en unas zonas del espacio y otros modelos lo harán en otras zonas, pero esos sobreajustes perderán fuerza en la combinación final de todos los modelos.\n",
    "\n",
    "### 24.4.1 `BaggingRegressor`\n",
    "Utilizando el algoritmo `BaggingRegressor` seremos capaces de efectuar un bagging. En `base_estimator` debemos indicarle qué sistema utilizaremos como estimador y en `n_estimators` lediremos el número de estimadores deseado. En https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html podemos consultar otros parámetros de este algoritmo.\n",
    "\n",
    "\n",
    "### 24.4.2 Random Forest\n",
    "\n",
    "El algoritmo de bagging más popular es el Random Forest, cuya implementación es `RandomForestRegressor`. Este algoritmo utilizará como estimadores árboles de regresión y promediará la predicción de todos los estimadores utilizados para generar la predicción final.\n",
    "\n",
    "En https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html se pueden encontrar más detalles de su uso que en gran medida son los mismos detalles presentes en `RandomForestClassifier`.\n",
    "\n",
    "También podemos obtener la relevancia de los atributos consultando el atributo `feature_importances_` después de haber entrenado.\n",
    "\n",
    "Vamos a probarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.035\n",
      "MSE = 8.987\n",
      "R2 = 0.912\n",
      "\n",
      "##########################################\n",
      "### Relevancia con RandomForest\n",
      "##########################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se crea un Random Forest\n",
    "sys = RandomForestRegressor(random_state=1234)\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Relevancia con RandomForest')\n",
    "print('##########################################')\n",
    "\n",
    "# obtenemos el número de atributos\n",
    "(num_ejemplos, num_atributos) = X.shape \n",
    "\n",
    "importances = sys.feature_importances_\n",
    "# ordenamos los atributos en orden descendente de importancia\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# los representamos gráficamente\n",
    "plt.figure()\n",
    "plt.title(\"Relevancia de los atributos RandomForest\") \n",
    "# [::-1] para que aparezcan en orden decreciente en la gráfica\n",
    "plt.barh(range(num_atributos), importances[indices[::-1]], tick_label=X.columns[indices[::-1]]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 24.5 Boosting\n",
    "En el boosting se utilizan modelos muy simples que se combinan para dar lugar a un modelo fuerte. Como modelos débiles, es muy común utilizar árboles de decisión con `max_depth=1`.\n",
    "\n",
    "En boosting se utilizan todos los ejemplos disponibles para entrenar (no como en bagging donde se hacían muestreos con reemplazamiento). La particularidad que tiene el boosting es que tras entrenar el primer modelo se utilizará el mismo para realizar una predicción para los ejemplos del conjunto de entrenamiento. Como es un modelo débil (muy limitado) en algunos ejemplos cometerá poco error (o ninguno) y en otros cometerá más error, así que se asignarán pesos a los ejemplos en función del error. Se entrenará un nuevo modelo que se utilizará para volver a realizar predicciones y que dará lugar a una nueva asignación de pesos. Este proceso se repetirá las veces que queramos.\n",
    "\n",
    "### 24.5.1 Ada Boost\n",
    "Para trabajar con problema de regresión podemos utilizar el `AdaBoostRegressor`: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "\n",
    "Sus hiperparámetros más importantes son los mismos que ya vimos en su versión como clasificador:\n",
    "- `base_estimator`, el algoritmo base que utilizaremos (que por defecto es un árbol de decisión con profundidad 1)\n",
    "- `n_estimators`, número de modelos que se entrenarán\n",
    "- `learning_rate`, valor en el rango (0, inf) que sirve para con cuánta intensidad intentará de corregir cada árbol los errores de los árboles anteriores. Valores pequeños harán que los pesos sean menos agresivos.\n",
    "\n",
    "También podemos obtener la relevancia de los atributos consultando el atributo `feature_importances_` después de haber entrenado.\n",
    "\n",
    "Vamos a probarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.766\n",
      "MSE = 13.675\n",
      "R2 = 0.867\n",
      "\n",
      "##########################################\n",
      "### Relevancia con AdaBoost\n",
      "##########################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se crea un AdaBoostRegressor\n",
    "sys = AdaBoostRegressor(random_state=1234)\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Relevancia con AdaBoost')\n",
    "print('##########################################')\n",
    "\n",
    "importances = sys.feature_importances_\n",
    "# ordenamos los atributos en orden descendente de importancia\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# los representamos gráficamente\n",
    "plt.figure()\n",
    "plt.title(\"Relevancia de los atributos AdaBoost\") \n",
    "# [::-1] para que aparezcan en orden decreciente en la gráfica\n",
    "plt.barh(range(num_atributos), importances[indices[::-1]], tick_label=X.columns[indices[::-1]]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 24.5.2 XGBoost\n",
    "\n",
    "El popular algoritmo de boosting XGBoost también puede ser utilizado en tareas de regresión utilizando la implementación `XGBRegressor` de su API para `sklearn` contenida en la librería `xgboost`.\n",
    "\n",
    "Podéis consultar sus hiperparámetros en https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "\n",
    "Veamos cuál es su rendimiento en este conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.994\n",
      "MSE = 9.117\n",
      "R2 = 0.911\n"
     ]
    }
   ],
   "source": [
    "# se crea un XGBRegressor\n",
    "sys = XGBRegressor()\n",
    "\n",
    "# se entrena y se evalúa\n",
    "sys.fit(X_train, y_train)\n",
    "y_pred = sys.predict(X_test)\n",
    "\n",
    "# se calculan las métricas\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"MAE = %.3f\\nMSE = %.3f\\nR2 = %.3f\" % (mae, mse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo de boosting suele obtener buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga los datos del fichero **airfoil_self_noise.data**. \n",
    "2. Separa el conjunto de datos para hacer un hold out 80-20.\n",
    "3. Evalúa el rendimiento de varios algoritmos de los comentados en esta sesión.\n",
    "4. Muestra, en forma de tabla, los resultados de las métricas explicadas en el notebook.\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64f5837e16e2c9074d8bf8acfd45df7ca64748c9ff033f1607453426c7868d4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
