{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 11 - Evaluación del rendimiento tras buscar hiperparámetros\n",
    "\n",
    "En la sesión de prácticas número 9 veíamos que para conocer el rendimiento que tendrá un modelo en producción es necesario evaluarlo con casos no vistos durante el entrenamiento.\n",
    "\n",
    "En la sesión de prácticas número 10 vimos cómo buscar los mejores hiperparámetros para una determinado algoritmo y para ello hemos utilizado todos los ejemplos que teníamos disponibles, así que el rendimiento que obtuvimos puede no ser el que tenga el modelo en producción.\n",
    "\n",
    "En esta sesión vamos a ver cómo obtener el rendimiento del modelo en producción a la vez que se buscan los mejores hiperparámetros.\n",
    "\n",
    "## 11.1 Método 1: GridSearchCV o RandomizedSearchCV dentro de una validación cruzada\n",
    "\n",
    "Como ya hemos indicado en otras ocasiones, la manera de ver qué rendimiento va a tener nuestro sistema en producción es probándolo ante casos no vistos, así que tendremos que simular esa situación.\n",
    "\n",
    "La mejor forma es mediante una validación cruzada:\n",
    "\n",
    "![Validación cruzada](fig_cv.png)\n",
    "\n",
    "Pero ahora, en cada iteración de la validación cruzada debemos realizar una búsqueda de hiperparámetros, ya sea utilizando `GridSearchCV()` o `RandomizedSearchCV()`. **¡Esto supone anidar dos validaciones cruzadas!**\n",
    "\n",
    "Veamos cómo implementarlo utilizando el conjunto que ya hemos utilizado en sesiones anteriores. Primero lo cargamos, lo preprocesamos y creamos una instancia del `KNN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atr1</th>\n",
       "      <th>atr2</th>\n",
       "      <th>atr3</th>\n",
       "      <th>atr4</th>\n",
       "      <th>atr5</th>\n",
       "      <th>atr6</th>\n",
       "      <th>atr7</th>\n",
       "      <th>atr8</th>\n",
       "      <th>atr9</th>\n",
       "      <th>atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>atr25</th>\n",
       "      <th>atr26</th>\n",
       "      <th>atr27</th>\n",
       "      <th>atr28</th>\n",
       "      <th>atr29</th>\n",
       "      <th>atr30</th>\n",
       "      <th>atr31</th>\n",
       "      <th>atr32</th>\n",
       "      <th>atr33</th>\n",
       "      <th>atr34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95378</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94520</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93988</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91050</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86467</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atr1  atr2     atr3     atr4     atr5     atr6     atr7     atr8  \\\n",
       "0       1     0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708   \n",
       "1       1     0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597   \n",
       "2       1     0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062   \n",
       "3       1     0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000   \n",
       "4       1     0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255   \n",
       "..    ...   ...      ...      ...      ...      ...      ...      ...   \n",
       "346     1     0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567   \n",
       "347     1     0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920   \n",
       "348     1     0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431   \n",
       "349     1     0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646   \n",
       "350     1     0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260   \n",
       "\n",
       "        atr9    atr10  ...    atr25    atr26    atr27    atr28    atr29  \\\n",
       "0    1.00000  0.03760  ...  0.56811 -0.51171  0.41078 -0.46168  0.21266   \n",
       "1    1.00000 -0.04549  ... -0.20332 -0.26569 -0.20468 -0.18401 -0.19040   \n",
       "2    0.88965  0.01198  ...  0.57528 -0.40220  0.58984 -0.22145  0.43100   \n",
       "3    0.00000  0.00000  ...  1.00000  0.90695  0.51613  1.00000  1.00000   \n",
       "4    0.77152 -0.16399  ...  0.03286 -0.65158  0.13290 -0.53206  0.02431   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "346  0.90441 -0.04622  ...  0.95378 -0.04202  0.83479  0.00123  1.00000   \n",
       "347  0.94590  0.01606  ...  0.94520  0.01361  0.93522  0.04925  0.93159   \n",
       "348  0.95584  0.02446  ...  0.93988  0.03193  0.92489  0.02542  0.92120   \n",
       "349  0.85746  0.00110  ...  0.91050 -0.02099  0.89147 -0.07760  0.82983   \n",
       "350  0.88928 -0.09139  ...  0.86467 -0.15114  0.81147 -0.04822  0.78207   \n",
       "\n",
       "       atr30    atr31    atr32    atr33    atr34  \n",
       "0   -0.34090  0.42267 -0.54487  0.18641 -0.45300  \n",
       "1   -0.11593 -0.16626 -0.06288 -0.13738 -0.02447  \n",
       "2   -0.17365  0.60436 -0.24180  0.56045 -0.38238  \n",
       "3   -0.20099  0.25682  1.00000 -0.32382  1.00000  \n",
       "4   -0.62197 -0.05707 -0.59573 -0.04608 -0.65697  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "346  0.12815  0.86660 -0.10714  0.90546 -0.04307  \n",
       "347  0.08168  0.94066 -0.00035  0.91483  0.04712  \n",
       "348  0.02242  0.92459  0.00442  0.92697 -0.00577  \n",
       "349 -0.17238  0.96022 -0.03757  0.87403 -0.16243  \n",
       "350 -0.00703  0.75747 -0.06678  0.85764 -0.06151  \n",
       "\n",
       "[351 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "346    1\n",
       "347    1\n",
       "348    1\n",
       "349    1\n",
       "350    1\n",
       "Name: clase, Length: 351, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################\n",
      "### K-vecinos\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "# se importan las librerías\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, ParameterGrid, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# se llama a la función read_csv\n",
    "# no tiene missing y las columnas están separadas por ','\n",
    "# tampoco cabecera, así que hay que dar nombre a las columnas (como en el names no vienen indicados creamos nombres)\n",
    "cabecera = ['atr'+str(x) for x in range(1,35)]\n",
    "cabecera.append('clase')\n",
    "df = pd.read_csv('ionosphere.data', names=cabecera)\n",
    "filas, columnas = df.shape\n",
    "\n",
    "\n",
    "# separamos los atributos y los almacenamos en X\n",
    "X = df.drop(['clase'], axis=1)\n",
    "display(X)\n",
    "\n",
    "class_enc = preprocessing.LabelEncoder()\n",
    "df['clase'] = class_enc.fit_transform(df['clase'])\n",
    "\n",
    "# separamos la clase y la almacenamos en Y\n",
    "y = df['clase']\n",
    "display(y)\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### K-vecinos')\n",
    "print('##########################################')\n",
    "# creamos una instancia del KNN\n",
    "knn_sis = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente definimos el espacio de búsqueda para los hiperparámetros y creamos una `GridSeachCV()`, que bien podría haber sido una `RandomizedSearchCV()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': ['uniform', 'distance'],\n",
       " 'p': [1, 2, 3],\n",
       " 'n_neighbors': [1, 2, 3, 4, 5]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se definen los valores de los hiperparámetros que se quieren  probar\n",
    "weights = ['uniform', 'distance'] # weights : {'uniform', 'distance'}\n",
    "p = [1, 2, 3] # p : int, default=2 => Euclídea\n",
    "n_neighbors = [1, 2, 3, 4, 5]\n",
    "\n",
    "# y se introducen en un diccionario\n",
    "hyperparameters = dict(weights=weights, p=p, n_neighbors=n_neighbors)\n",
    "\n",
    "display(hyperparameters)\n",
    "\n",
    "# se crea un generador de folds estratificados partiendo el conjunto en 5 trozos\n",
    "folds5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# creamos una grid search para el KNN donde le pasamos los hiperparámetros que queremos probar\n",
    "gs = GridSearchCV(knn_sis, hyperparameters, scoring='accuracy', cv=folds5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ejecutamos la función `cross_val_score()` que efectuará la validación cruzada que deseemos. En este caso vamos a utilizar 10 folds, por tanto, el número de entrenamientos será $2 \\times 3 \\times 5 \\times 5 \\times 10 = 1500$ (2 valores para `weights`, 3 valores para `p`, 5 valores para `n_neighbors`, la grid search tiene 5 folds y la validación cruzada 10 folds).\n",
    "\n",
    "Para que no se nos llene la consola de ejecuciones es recomendable bajar el `verbose` a 1 tanto en `GridSearchCV()` como en `cross_val_score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "KNN (mean+-std): 0.9117 +- 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "# se crea un generador de folds estratificados partiendo el conjunto en 10 trozos\n",
    "folds10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "# se realiza la validación cruzada para el KNN\n",
    "scores_knn = cross_val_score(gs, X, y, cv=folds10, scoring='accuracy', verbose=1)\n",
    "print(\"KNN (mean+-std): %0.4f +- %0.4f\" % (scores_knn.mean(), scores_knn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el tiempo de ejecución puede comenzar a elevarse peligrosamente, así que cuando necesitemos utilizar esta técnica debemos ser conscientes del número de ejecuciones que implica del tiempo que puede llegar a tardar.\n",
    "\n",
    "Un inconveniente que se presenta es el hecho de que en cada iteración de la validación cruzada puede resultar una combinación de hiperparámetros diferentes, así que aunque hemos sido capaces de obtener el rendimiento en producción, no sabemos cuáles son los hiperparámetros que debemos utilizar. Esto se solucionaría realizando una `GridSearchCV()` como hacíamos en la práctica anterior y así tendríamos los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Método 2: Entrenamiento - validación - test\n",
    "\n",
    "Cuando anidar dos validaciones cruzadas suponga que el tiempo de ejecución es demasiado elevado, entonces podemos recurrir a este método que como veremos es menos fiable, pero mucho menos costoso computacionalmente. Consiste en dividir el conjunto de datos varias veces:\n",
    "\n",
    "![Train-val-test](fig_train_val_test.png) \n",
    "\n",
    "Veamos cómo se procede:\n",
    "1. Primero se separa en un conjunto para entrenar (training set) y en otro para evaluar (test set). El conjunto de test no podremos utilizarlo durante la búsqueda de hiperparámetros.\n",
    "2. Así que para buscar los hiperparámetros necesitamos hacer otra división, pero esta vez del conjunto de entrenamiento: tendremos un conjunto para entrenar las diferentes combinaciones de hiperparámetros y las probaremos sobre el conjunto de validación que suele llamarse *validation set* o *development set*. \n",
    "3. Una vez que se ha encontrado la mejor combinación de hiperparámetros habrá que entrenar el sistema utilizando el conjunto de entrenmaiento completo y evaluar sobre el conjunto de test para así tener una aproximación al rendimiento que el modelo tendrá ante casos no vistos.\n",
    "\n",
    "Veamos cómo implementarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de ejemplos inicial\n",
      "X: 351\n",
      "\n",
      "Número de ejemplos para train y test\n",
      "X_train: 263\n",
      "X_test: 88\n",
      "\n",
      "Número de ejemplos tras dividir nuevamente el train\n",
      "X_tr: 197\n",
      "X_val: 66\n"
     ]
    }
   ],
   "source": [
    "# separamos los datos en training set y test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234, stratify=y)\n",
    "\n",
    "# separamos los datos de entrenamiento en train y val para la búsqueda de hiperparámetros\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1234, stratify=y_train)\n",
    "\n",
    "print(\"\\nNúmero de ejemplos inicial\")\n",
    "print(\"X:\", X.shape[0])\n",
    "\n",
    "print(\"\\nNúmero de ejemplos para train y test\")\n",
    "print(\"X_train:\", X_train.shape[0])\n",
    "print(\"X_test:\", X_test.shape[0])\n",
    "\n",
    "print(\"\\nNúmero de ejemplos tras dividir nuevamente el train\")\n",
    "print(\"X_tr:\", X_tr.shape[0])\n",
    "print(\"X_val:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que hacemos es separar, utilizando `train_test_split()`, el conjunto de datos en los conjuntos *train* y *test* (esta función ya realiza un barajado de los ejemplos antes de partir). El conjunto de test quedará reservado para la evaluación final actuando como conjunto de casos no vistos, así que el conjunto de train es el que utilizaremos para la búsqueda de hiperparámetros.\n",
    "\n",
    "Por tanto, debemos volver a dividirlo para tener un subconjunto con el que entrenar (`tr`) y otro con el que evaluar o validar el rendimiento (`val`).\n",
    "\n",
    "En ambas divisiones hemos separado un 25% de los ejemplos para test y validación. Este porcentaje dependerá de cada conjunto de datos que estemos tratando. Lo deseable es siempre tener conjuntos de tests que sean representativos, así que cuanto mayor sea mejor, sin embargo, si tenemos pocos datos en el conjunto, reservar muchos datos para test puede ser contraproducente puesto que no estaríamos utilizando esos datos para entrenar el modelo.\n",
    "\n",
    "Ese es el problema de esta forma de buscar hiperparámetros.\n",
    "\n",
    "Si nos fijamos en la salida del código anterior, contamos inicialmente con 351 ejemplos y hemos apartado 88 para la evaluación final ¿son representativos? Esperamos que sí. Para buscar hyperparámetros vamos a utulizar los 263 ejemplos de conjunto de entrenamiento que dividimos nuevamente quedando 66 ejemplos para la validación, ¿son representativos? Volvemos a esperar que sí. Si os dáis cuenta, estamos fiando la búsqueda de hiperparámetros al rendimiento que tengan los modelos sobre 66 ejemplos. Puede salir bien o puede salir mal, depende de si son representativos o no.\n",
    "\n",
    "Una vez hechas las divisiones se preparan las combinaciones de hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': ['uniform', 'distance'],\n",
       " 'p': [1, 2, 3],\n",
       " 'n_neighbors': [1, 2, 3, 4, 5]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se definen los valores de los hiperparámetros que se quieren  probar\n",
    "weights = ['uniform', 'distance'] # weights : {'uniform', 'distance'}\n",
    "p = [1, 2, 3] # p : int, default=2 => Euclídea\n",
    "n_neighbors = [1, 2, 3, 4, 5]\n",
    "\n",
    "# y se introducen en un diccionario\n",
    "hyperparameters = dict(weights=weights, p=p, n_neighbors=n_neighbors)\n",
    "\n",
    "display(hyperparameters)\n",
    "\n",
    "# creamos un grid con los hiperparámetros\n",
    "grid = ParameterGrid(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esencia se hace lo mismo que habíamos hecho para el `GridSearchCV()`, la única diferencia es la última línea en la que utilizamos la función `ParameterGrid()` para que genere todas las combinaciones posible de hiperparámetros con los valores que le hemos dado.\n",
    "\n",
    "Esas combinaciones las utilizaremos dentro de un bucle, como vemos en el siguiente trozo de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=1, p=1)\n",
      "KNeighborsClassifier(n_neighbors=1, p=1, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=1, p=3)\n",
      "KNeighborsClassifier(n_neighbors=1, p=3, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=2, p=1)\n",
      "KNeighborsClassifier(n_neighbors=2, p=1, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      "KNeighborsClassifier(n_neighbors=2, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=2, p=3)\n",
      "KNeighborsClassifier(n_neighbors=2, p=3, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=3, p=1)\n",
      "KNeighborsClassifier(n_neighbors=3, p=1, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=3, p=3)\n",
      "KNeighborsClassifier(n_neighbors=3, p=3, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=4, p=1)\n",
      "KNeighborsClassifier(n_neighbors=4, p=1, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=4)\n",
      "KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
      "KNeighborsClassifier(n_neighbors=4, p=3)\n",
      "KNeighborsClassifier(n_neighbors=4, p=3, weights='distance')\n",
      "KNeighborsClassifier(p=1)\n",
      "KNeighborsClassifier(p=1, weights='distance')\n",
      "KNeighborsClassifier()\n",
      "KNeighborsClassifier(weights='distance')\n",
      "KNeighborsClassifier(p=3)\n",
      "KNeighborsClassifier(p=3, weights='distance')\n",
      "Mejor combinación de hiperparámetros: {'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}\n",
      "Mejor rendimiento obtenido: 0.9242\n"
     ]
    }
   ],
   "source": [
    "# inicializamos variables para almacenar los mejores\n",
    "best_acc = 0\n",
    "best_hyperparams = None\n",
    "\n",
    "# hacemos un bucle para probar todas las combinaciones\n",
    "for hyperparams in grid:\n",
    "    knn_sis.set_params(**hyperparams)      # asignamos los hyperparámetros\n",
    "    print(knn_sis)\n",
    "    knn_sis.fit(X_tr, y_tr)                 # entrenamos con X_tr\n",
    "    y_val_pred = knn_sis.predict(X_val)     # evaluamos con X_val\n",
    "    acc = accuracy_score(y_val, y_val_pred) # calculamos accuracy y_val vs y_val_pred\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_hyperparams = hyperparams\n",
    "\n",
    "print(\"Mejor combinación de hiperparámetros:\", best_hyperparams)\n",
    "print(\"Mejor rendimiento obtenido: %.4f\" % best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando queremos pasarle varios hiperparámetros a un sistema utilizando `set_params()` debemos pasárselos como argumento en un diccionario con la sintaxis `**diccionario`.\n",
    "\n",
    "Más detalles en: https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters\n",
    "\n",
    "En cada iteración se asigna al sistema la combinación de hiperparámetros correspondiente y se entrena utilizando la partición de datos de entrenamiento (para la búsqueda) y se evalúa sobre la partición de validación.\n",
    "\n",
    "Si se obtiene un rendimiento mejor, entonces se almacena la accuracy y la combinación de hiperparámetros.\n",
    "\n",
    "Al finalizar el bucle ya tendremos la mejor combinación de hiperparámetros y, como se ve en el código siguiente, ya solo nos queda entrenar el modelo con el conjunto de entrenamiento al completo utilizando la mejor combinación de hyperparámetros y evaluar sobre el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=2, p=1)\n",
      "Accuracy sobre casos no vistos: 0.9205\n"
     ]
    }
   ],
   "source": [
    "# asignamos los mejores hiperparámetros\n",
    "best_model = knn_sis.set_params(**best_hyperparams)\n",
    "print(best_model)\n",
    "\n",
    "# reentrenamos el vecino más próximo\n",
    "best_model.fit(X_train, y_train)            # se entrena sobre la partición de train\n",
    "y_test_pred = best_model.predict(X_test)    # se predice sobre la partición de test\n",
    "print(\"Accuracy sobre casos no vistos: %.4f\" % accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Mezcla de los dos métodos\n",
    "\n",
    "También es posible realizar una combinación de los dos métodos expuestos anteriormente.\n",
    "\n",
    "Podríamos hacer un hold-out 70-30 y realizar una búsqueda de hiperparámetros sobre el conjunto de entrenamiento utilizando `GridSearchCV` o `RandomizedSearchCV`. \n",
    "\n",
    "Siguiendo este procedimiento eliminaríamos el exceso de tiempo que supone la validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga el fichero **heart_failure_clinical_records_dataset.csv** (es un archivo de texto). \n",
    "2. Utiliza los dos métodos vistos en esta sesión para calcular el rendimiento del sistema tras la búsqueda de hiperparámetros.\n",
    "\n",
    "**OJO**, ten en cuenta que los atributos tienen escalas diferentes, así que deberás crear un pipeline.\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
