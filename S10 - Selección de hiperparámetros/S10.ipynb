{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 10 - Selección de hiperparámetros\n",
    "\n",
    "Cuando se está entrenando un modelo para resolver una determinada tarea hay dos elementos que cobran especial importancia:\n",
    "1. Los **parámetros**. Son los valores que durante el proceso de entrenamiento del modelo deben aprenderse. Los parámetros serán los responsables de que el sistema tenga (o no) un buen rendimiento en las predicciones. Por ejemplo, cuando se hace regresión lineal, los coeficientes que se aprenden son lo que aquí llamamos parámetros; también lo serían los pesos de una red neuronal, los valores de corte de un árbol de decisión,...\n",
    "2. Los **hiperparámetros**. Son características particulares de cada algoritmo que pueden hacer que el comportamiento del modelo entrenado sea diferente. Por ejemplo, en el KNN el número de vecinos (`n_neighbors`) es un hiperparámetro y como vimos en la práctica anterior, el rendimiento del modelo será diferente.\n",
    "\n",
    "Una regla sencilla para saber qué es un hiperparámetro y qué es un parámetro es la siguiente: **las decisiones que tomamos antes de entrenar un modelo son o afectan a hiperparámetros, mientras que los términos que aprende el modelo durante el entrenamiento son parámetros.**\n",
    "\n",
    "El KNN tiene varios hiperparámetros:\n",
    "- el número de vecinos (`n_neighbors`). Debe ser un número entero mayor o igual que 1\n",
    "- si se pondera el voto de los vecinos (`weights`). Puede tomar los valores `uniform` o `distance`, donde el primero indica que todos los votos pesan lo mismo y el segundo que se pondera en función de la distancia.\n",
    "- la distancia utilizada (`p`). Por defecto se utiliza la distancia de Minkowski, que cuando `p=1` se corresponde con la distancia Manhattan y cuando `p=2` con la distancia Euclídea. `p` debe ser un valor  entero mayor o igual que 1.\n",
    "\n",
    "$$D(a,b) = \\left(\\sum_{i}(a_i-b_i)^p\\right)^{1/p}$$\n",
    "\n",
    "Sin embargo el KNN no tiene parámetros, ya que no tiene nada que aprender puesto que simplemente memoriza los ejemplos para calcular distancias durante la predicción.\n",
    "\n",
    "En esta práctica vamos a ver cómo se seleccionan los hiperparámetros de los modelos. \n",
    "\n",
    "## 10.1 Grid Search\n",
    "\n",
    "Cuando queremos utilizar una búsqueda de hiperparámetros por fuerza bruta donde queremos que se prueben todas las combinaciones posibles para los valores de hiperparámetros que indicamos, entonces debemos utilizar una *grid search*, que en `sklearn` se implementa mediante la clase `GridSearchCV`.\n",
    "\n",
    "La `GridSearchCV` realizará una validación cruzada para cada una de las combinaciones de hiperparámetros posibles y se quedará con aquella combinación que produzca el mejor rendimiento.\n",
    "\n",
    "Vamos a ver cómo realizar esta búsqueda de hiperparámetros utilizando nuevamente el conjunto `ionosphere`, para ello lo primero que vamos a hacer es cargar el conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se importan las librerías\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# se llama a la función read_csv\n",
    "# no tiene missing y las columnas están separadas por ','\n",
    "# tampoco cabecera, así que hay que dar nombre a las columnas (como en el names no vienen indicados creamos nombres)\n",
    "cabecera = ['atr'+str(x) for x in range(1,35)]\n",
    "cabecera.append('clase')\n",
    "df = pd.read_csv('ionosphere.data', names=cabecera)\n",
    "filas, columnas = df.shape\n",
    "\n",
    "# la clase está en la última columna \n",
    "# separamos los atributos y los almacenamos en X\n",
    "X = df.iloc[:,0:(columnas-1)]\n",
    "display(X)\n",
    "\n",
    "class_enc = preprocessing.LabelEncoder()\n",
    "df['clase'] = class_enc.fit_transform(df['clase'])\n",
    "\n",
    "# separamos la clase y la almacenamos en Y\n",
    "y = df.iloc[:,(columnas-1)]\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el conjunto de datos vamos a crear un sistema KNN y a configurar los hiperparámetros que queremos probar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una instancia del KNN\n",
    "knn_sis = KNeighborsClassifier()\n",
    "\n",
    "# se definen los valores de los hiperparámetros que se quieren  probar\n",
    "weights = ['uniform', 'distance'] # weights : {'uniform', 'distance'}\n",
    "p = [1, 2, 3] # p : int, default=2 => Euclídea\n",
    "n_neighbors = [1, 2, 3, 4, 5]\n",
    "\n",
    "# y se introducen en un diccionario\n",
    "hyperparameters = dict(weights=weights, p=p, n_neighbors=n_neighbors)\n",
    "\n",
    "display(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manera más sencilla de hacerlo es como vemos en el código: para cada hiperparámetro se indican los valores que se quieren probar en una lista y luego se crea un diccionario con todos los hiperparámetros.\n",
    "\n",
    "Posteriormente, debemos crear la grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea un generador de folds estratificados partiendo el conjunto en 5 trozos\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# creamos una grid search para el KNN donde le pasamos los hiperparámetros que queremos probar\n",
    "gs = GridSearchCV(knn_sis, hyperparameters, scoring='accuracy', cv=folds, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe indicar cuál es el algoritmo y cuáles son los parámetros a probar. También podemos indicarle qué métrica queremos utilizar para medir el rendimiento y los folds que vamos a utilizar en la validación cruzada (es importante garantizar el barajado de alguna manera para evitar sesgos). \n",
    "\n",
    "`verbose=3` servirá para ir viendo una traza de lo que `GridSearchCV()` va haciendo; podemos utilizar otros niveles inferiores de `verbose` (2, 1 o 0) si no queremos tanta información.\n",
    "\n",
    "En las búsquedas de hiperparámetros es recomendable paralelizar las ejecuciones, por eso se suele utilizar `n_jobs=-1`. En el ejemplo que estamos llevando a cabo, para el hiperparámetro `weights` queremos probar 2 valores, para `p` 3 valores y para `n_neighbors` 5 valores. Esto hace un total de $2 \\times 3 \\times 5 = 30$ posibles combinaciones. Como cada combinación se prueba con una validación cruzada de 5 folds, se realizarán en total $30 \\times 5 = 150$ entrenamientos diferentes.\n",
    "\n",
    "Para realizar la búsqueda de los hiperparámetros debemos entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos la búsqueda\n",
    "res_gs = gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparecerá una línea por cada uno de los entrenamientos donde se detallará a qué combinación corresponde. Si no se hubiese paralelizado el entrenamiento aparecerían las ejecuciones ordenadas.\n",
    "\n",
    "Una vez finalizada la búsqueda, `GridSearchCV()` realiza un entrenamiento utilizando todos los ejemplos disponibles y con la combinación de hiperparámetros que mejor rendimiento presentó en validación cruzada. \n",
    "\n",
    "En https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html podemos ver que el resultado de la `GridSearchCV()` contiene mucha información. Podemos acceder a tiempos de ejecución o a resultados de cada validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones probadas\n",
    "print(\"Combinaciones de hiperparámetros probadas:\\n\", res_gs.cv_results_['params'])\n",
    "\n",
    "# resultados\n",
    "print(\"Accuracy media de cada combinación:\\n\", res_gs.cv_results_['mean_test_score'])\n",
    "print(\"Desviación en cada combinación:\\n\", res_gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también consultar cuál ha sido el mejor rendimiento obtenido y la combinación de hiperparámetros que lo propició. Además, `best_estimator_` contiene el modelo entrenado con la mejor combinación y utilizando todos los ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejor combinación de hiperparámetros:\", res_gs.best_params_)\n",
    "print(\"Mejor rendimiento obtenido: %.4f\" % res_gs.best_score_)\n",
    "\n",
    "# modelo entrenado\n",
    "best_model = res_gs.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al imprimir `best_model` no se especifica `weights='uniform'` porque ese es su valor por defecto en `KNeighborsClassifier()`.\n",
    "\n",
    "## 10.2 Búsqueda aleatoria\n",
    "\n",
    "Cuando el espacio de búsqueda es demasiado grande y no se pueden probar todas las combinaciones posibles por resultar infinitas o porque nos extenderíamos demasiado en el tiempo, entonces debemos optar por realizar una búsqueda en la que se prueben combinaciones seleccionadas al azar.\n",
    "\n",
    "Sobre el mismo ejemplo que estamos siguiendo, imaginemos que queremos probar combinaciones de hiperparámetros utilizando valores para el número de vecinos entre 1 y 50, para la `p` de Minkowski valores entre 1 y 10 y ponderando o no las distancias. Esto haría un total de $50 \\times 10 \\times 2 = 1000$ posibles combinaciones de hiperparámetros. \n",
    "\n",
    "Si probar estas 1000 combinaciones es muy costoso, tenemos la posibilidad de utilizar una `RandomizedSearchCV()` que probará un número determinado de combinaciones de hiperparámetros: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV \n",
    "\n",
    "A la hora de definir los valores posibles para los hiperparámetros, tendremos la posibilidad de pasarle una distribución para la generación de valores para los hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribución uniforme entre 1 y 50\n",
    "dist_n_neighbors = randint(1, 50)\n",
    "\n",
    "# distribución uniforme entre 1 y 10\n",
    "dist_p = randint(1,10)\n",
    "\n",
    "# se especifican los valores posibles y muestreará de forma uniforme\n",
    "weights = ['uniform', 'distance'] \n",
    "\n",
    "# se crea el diccionario de hiperparámetros\n",
    "hyperparameters = dict(weights=weights, p=dist_p, n_neighbors=dist_n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar las distribuciones podemos acudir a la librería `scipy` donde encontramos funciones como `randint()` que genera valores enteros en un intervalo, `uniform()` que lo hace para números reales o `norm()` que los genera siguiendo una distribución normal.\n",
    "\n",
    "Una vez que tenemos el diccionario de hiperparámetros preparado tenemos que crear el `RandomizedSearchCV()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(knn_sis, hyperparameters, scoring='accuracy', random_state=1234, n_iter=100, cv=folds, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de los datos que ya se pasaban a `GridSearchCV()` en este caso debemos pasarle `random_state` si queremos que los resultados sean reproducibles y el parámetro `n_iter` con el que le indicamos el número de combinaciones que queremos probar. En este ejemplo se indica `n_iter=100` con lo que se probaría un 10% de total de combinaciones posibles. `RandomizedSearchCV()` efectúa un muestreo sin reemplazamiento.\n",
    "\n",
    "Nos queda entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos\n",
    "res_rs = rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ver los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Hiperparámetros:\", res_rs.cv_results_['params'])\n",
    "print(\"Accuracy:\", res_rs.cv_results_['mean_test_score'])\n",
    "print(\"Desviación:\", res_rs.cv_results_['std_test_score'])\n",
    "print(\"Mejor combinación de hiperparámetros:\", res_rs.best_params_)\n",
    "print(\"Mejor rendimiento obtenido: %.4f\" % res_rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que obtenemos un resultado un poco peor que con `GridSearchCV()`, sin embargo, hemos explorado un espacio mucho más grande.\n",
    "\n",
    "A veces, se utiliza `RandomizedGridSearch()` para acotar el espacio de búsqueda y posteriormente se realiza una `GridSearchCV()` para realizar una búsqueda más exhaustiva en la zona del espacio de hiperparámetros que indique la `RandomizedGridSearch()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga el fichero **heart_failure_clinical_records_dataset.csv** (es un archivo de texto). \n",
    "2. Realiza una búsqueda aleatoria utilizando valores para el número de vecinos entre 1 y 50, para la `p` de Minkowski valores entre 1 y 10 y ponderando o no las distancias. **OJO**, ten en cuenta que los atributos tienen escalas diferentes, así que deberás crear un pipeline.\n",
    "3. Una vez acotado el espacio de búsqueda, realiza una búsqueda más exhaustiva utilizando una `GridSearchCV()`.\n",
    "\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
