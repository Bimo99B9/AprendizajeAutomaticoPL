{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo de AA1](logo_AA1_texto_small.png) \n",
    "# Sesión 27 - Preprocesado con atributos de tipos diferentes\n",
    "\n",
    "A lo largo de todas las sesiones prácticas hemos estado utilizando diferentes algoritmos que nos han permitido trabajar con los datos. Podemos clasificar estos algoritmos como *Transformadores* o *Estimadores*:\n",
    "- **Tansformadores**. Un *transformador* es un objeto que tiene los métodos `fit()` y `transform()` y suele utilizarse para el preprocesado de los datos. Los transformadores pueden utilizarse para la limpieza de los datos, el escalado de atributos, la reducción de la dimensionalidad,...\n",
    "- **Estimadores**. Un *estimador* es un objeto que es capaz de aprender a partir de los datos y generar un modelo con capacidades predictivas. Estos objetos tienen los métodos `fit()` y `predict()`.\n",
    "\n",
    "Los conjuntos de datos que hemos utilizado hasta el momento han sido conjuntos de datos en los que todos los atributos se preprocesaban de la misma manera o se daban circunstancias que nos permitían preprocesarlos de manera manual.\n",
    "\n",
    "Sin embargo, en los conjuntos de datos reales podemos encontrarnos con que los atributos necesitan preprocesarse de manera diferente. Por ejemplo, los atributos de tipo categórico querremos codificarlos mediante una codificación one-hot, los atributos numéricos podemos querer escalarlos de alguna manera y los atributos binarios puede ser que queramos dejarlos tal y como están.\n",
    "\n",
    "También se puede dar el caso de que tengamos valores desconocidos y que necesitemos *imputar* valores. Esto se hará de manera diferente dependiendo del tipo de atributo de que se trate.\n",
    "\n",
    "Y, por supuesto, debemos tener en cuenta también que los transformadores deben realizar el `fit()` sobre el conjunto de entrenamiento, ya que si lo hacemos sobre todo el conjunto de datos estaríamos utilizando los datos de test durante el proceso de entrenamiento y eso no es correcto.\n",
    "\n",
    "Para solucionar este último punto hemos utilizado los `Pipeline` y nos han resultado muy útiles puesto que podíamos enlazar por ejemplo, un `StandardScaler` y una `SVR`. Sin embargo, un `Pipeline` creado de tal manera aplicaría el `StandarScaler` a todos los atributos, incluso a los categóricos si los hubiese.\n",
    "\n",
    "## 27.1 Preprocesado de atributos diferenciado\n",
    "\n",
    "Dentro de `Scikit-learn` podemos encontrar una herramienta muy útil para el tratamiento deferenciado de grupos de atributos. Esa herramienta es el `ColumnTransformer` y vamos a ir viendo poco a poco cómo se utiliza.\n",
    "\n",
    "Para empezar vamos a cargar un conjunto de datos que necesita preprocesar unos atributos de una manera y otros de otra manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# los valores están separados por uno a varios espacios en blanco\n",
    "# hay valores desconocido identificados como '?'\n",
    "cabecera = ['class (mpg)','cylinders','displacement','horsepower','weight','acceleration', 'model year', 'origin', 'car name']\n",
    "df = pd.read_csv('auto-mpg.data', sep='\\s+', names=cabecera, na_values='?')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el fichero **auto-mpg.names** se describen los atributos de la siguiente manera:\n",
    "\n",
    "1. mpg:           continuous\n",
    "2. cylinders:     multi-valued discrete\n",
    "3. displacement:  continuous\n",
    "4. horsepower:    continuous\n",
    "5. weight:        continuous\n",
    "6. acceleration:  continuous\n",
    "7. model year:    multi-valued discrete\n",
    "8. origin:        multi-valued discrete\n",
    "9. car name:      string (unique for each instance)\n",
    "\n",
    "*mpg* se refiere a \"miles per gallon\", es la clase que se desea aprender. En este conjunto se presentan características de diferentes modelos de coches y lo que se pretende es ver si se puede predecir el consumo del coche en función de esos atributos.\n",
    "\n",
    "El último atributo, *car name*, es el nombre del modelo de coche y no aporta información relevante, así que vamos a eliminarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se elimina car name porque no aporta información al problema\n",
    "df = df.drop(columns=['car name'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos *displacement*, *horsepower*, *weight* y *acceleration* vienen marcados como continuos en el fichero names.\n",
    "\n",
    "Se indica que los atributos *cylinders* y *model year* son *multi-valued discrete*. Si observamos los datos vemos que el primero indica el número de cilindros y que tiene un orden ($4 \\lt 6 \\lt 8$), así que podemos considerarlo también de tipo numérico. *model year* indica el año de lanzamiento del modelo al mercado y tiene también un sentido numérico. Podríamos considerarlos ordinales, pero al ser números y tener relevancia su orden vamos a considerarlos como atributos de tipo numérico.\n",
    "\n",
    "El atributo *origin* tiene 3 posibles valores que se corresponden con el origen de la marca del coche:\n",
    "- 1 -> América\n",
    "- 2 -> Europa\n",
    "- 3 -> Japón\n",
    "\n",
    "Así que este atributo es de tipo categórico.\n",
    "\n",
    "Por tanto, **tenemos un atributo de tipo categórico y el resto de tipo numérico y deben ser tratados de manera diferente en el preprocesado de datos**.\n",
    "\n",
    "Con el fin de poder visualizar mejor los pasos que vamos dando, en un principio vamos a utilizar únicamente 5 ejemplos a modo prueba. Más adelante ya utilizaremos todo el conjunto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se barajan los ejemplos y nos quedamos solo con los 5 primeros\n",
    "df5 = df.sample(random_state=2, n=5)\n",
    "\n",
    "# la clase está en la primera columna!\n",
    "# separamos las últimas columnas y las almacenamos en X\n",
    "X = df5.iloc[:,1:]\n",
    "# X = df.drop(['class (mpg)'], axis=1)\n",
    "\n",
    "# separamos la clase\n",
    "y = df5.iloc[:,0]\n",
    "# y = df['class (mpg)'] \n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Hold-out 80-20')\n",
    "print('##########################################')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "print(\"X_train:\")\n",
    "display(X_train)\n",
    "print(\"X_test:\")\n",
    "display(X_test)\n",
    "print(\"y_train:\")\n",
    "display(y_train)\n",
    "print(\"y_test:\")\n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el barajado hemos utilizado una semilla de aletorios que selecciona 5 ejemplos adecuados para lo que queremos mostrar (por eso no hemos utilizado la semilla que utilizamos habitualmente).\n",
    "\n",
    "Vamos ahora a crear grupos de atributos. Antes vimos que salvo el atributo *origin* que es de tipo categórico, el resto de atributos es de tipo numérico, así que vamos a crear dos listas que identifiquen a los atributos de ambos grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se identifican los grupos de atributos quese quieren preprocesar\n",
    "atr_nume = X_train.columns.drop('origin')\n",
    "atr_cate = ['origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podría haber otros grupos de atributos, como por ejemplo los binarios, y también podría haber atributos a los que no se les quiera hacer ningún preprocesado.\n",
    "\n",
    "Ahora vamos a definir lo que querríamos hacer con los atributos de cada uno de esos grupos utilizando un `Pipeline` para cada grupo.\n",
    "\n",
    "Empezamos por los categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos pipeline para atributos categóricos\n",
    "pipe_cate = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('oh', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este `Pipeline` estamos indicando que queremos que a los atributos categóricos primero se les asigne un valor a sus valores desconocidos. En este caso estamos indicando que si no se conoce el lugar de origen de la marca que se ponga un 0, que es una manera de decir que no es de los lugares conocidos.\n",
    "\n",
    "Posteriormente se realiza una codificación one-hot. En este caso vamos a utilizar `OneHotEncoder`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?highlight=onehotencoder#sklearn.preprocessing.OneHotEncoder \n",
    "\n",
    "Vamos a probar el `Pipeline` para ver lo que hace, aunque más adelante lo utilizaremos de manera más sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el pipeline sobre la columna 'origin'\n",
    "pipe_cate.fit(X_train['origin'].values.reshape(-1,1))\n",
    "\n",
    "display(X_train)\n",
    "\n",
    "# tranformamos la columna 'origin' de X_train\n",
    "pipe_cate.transform(X_train['origin'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el pipeline funciona puesto que asigna una columna a cada valor posible y transforma los ejemplos correctamente.\n",
    "\n",
    "Vamos ahora a hacer el pipeline para los atributos numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos pipeline para atributos numéricos\n",
    "pipe_nume = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se utiliza un *imputer* que asigna la mediana a los valores desconocidos y posteriormente estandariza.\n",
    "\n",
    "Vamos a verlo funcionar en el atributo *horsepower*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el pipeline sobre la columna 'horsepower'\n",
    "pipe_nume.fit(X_train['horsepower'].values.reshape(-1,1))\n",
    "\n",
    "display(X_train)\n",
    "\n",
    "# tranformamos la columna 'horsepower' de X_train\n",
    "pipe_nume.transform(X_train['horsepower'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que ha hecho ha sido asignar la mediana (88) al valor desconocido y después ha estandarizado los valores resultando los valores que se muestran.\n",
    "\n",
    "Ya hemos visto que ambos pipelines funcionan de forma correcta si les damos los atributos adecuados. Ahora es cuando entra en juego el `ColumnTransformer` para facilitarnos la vida: https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Atributos numéricos:\", atr_nume)\n",
    "print(\"Atributos categóricos:\", atr_cate)\n",
    "\n",
    "# definimos un ColumnTransformer para tratar los atributos de manera diferente\n",
    "# y los que no pertenezcan a ninguno de los grupos se deja tal cual está\n",
    "at_transformer = ColumnTransformer([\n",
    "    ('at_cat', pipe_cate, atr_cate),\n",
    "    ('at_num', pipe_nume, atr_nume)], \n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le hemos indicado que a los atributos categóricos les aplique el pipeline `pipe_cate` y a los numéricos el pipeline `pipe_nume`. Si hubiese más atributos que no perteneciesen a ninguno de esos dos grupos no se haría nada con ellos (`remainder='passthrough'`).\n",
    "\n",
    "**IMPORTANTE:** En el transformer hemos situado el pipeline de los atributos categóricos primero y el de los numéricos después. Esto implica que tras aplicar el transformer aparecerán primero los atributos categóricos y después los numéricos. Además, seguirán el orden que hayamos indicado en las listas correspondientes. \n",
    "\n",
    "Ahora podemos entrenar este *transformer* y ver su resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo entrenamos\n",
    "at_transformer.fit(X_train)\n",
    "\n",
    "# para comprender mejor la salida, vamos a mostrar los datos dentro de un dataframe con los nombres adecuados\n",
    "# Los atributos categóricos en formato one-hot se nombrará como 'nombreAtributo_valorAtributo'\n",
    "nombres_oh_atr_cat = at_transformer.named_transformers_['at_cat']['oh'].get_feature_names_out(atr_cate)\n",
    "nombres_columnas = np.append(nombres_oh_atr_cat, atr_nume)\n",
    "print(nombres_columnas)\n",
    "\n",
    "print(\"####################### Conjunto de entrenamiento #######################\")\n",
    "# mostramos los datos originales\n",
    "display(X_train)\n",
    "#mostramos los datos transformados (dentro de un dataframe)\n",
    "display(pd.DataFrame(at_transformer.transform(X_train), columns=nombres_columnas))\n",
    "\n",
    "print(\"####################### Conjunto de test #######################\")\n",
    "# mostramos los datos originales\n",
    "display(X_test)\n",
    "#mostramos los datos transformados (dentro de un dataframe)\n",
    "display(pd.DataFrame(at_transformer.transform(X_test), columns=nombres_columnas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los conjuntos de entrenamiento y test se han generado de manera correcta realizando preprocesados diferentes en cada atributo en función de lo que le hemos indicado.\n",
    "\n",
    "Estas tranformaciones las hemos hecho nosotros llamando a `fit()` y a `transform()` por motivos didácticos para que viésemos lo que va sucediendo paso a paso. \n",
    "\n",
    "En la práctica podemos hacer que todo sea más automático utilizando un pipeline que realice las transformaciones y luego llame a un estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline que realiza el preprocesado y lo encadena con un estimador\n",
    "sys_prep_svr = Pipeline([\n",
    "    ('atr_trans', at_transformer),\n",
    "    ('sys', SVR())\n",
    "])\n",
    "\n",
    "# entrenamos\n",
    "sys_prep_svr.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos una predicción sobre el mismo conjunto de entrenamiento\n",
    "y_train_pred = sys_prep_svr.predict(X_train)\n",
    "print(\"Predicciones en el conjunto de entrenamiento:\", y_train_pred)\n",
    "\n",
    "# Realizamos una predicción sobre el conjunto de test\n",
    "y_test_pred = sys_prep_svr.predict(X_test)\n",
    "print(\"Predicciones en el conjunto de test:         \", y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, hemos creado un sistema que realiza todo el proceso de preprocesado y generación del modelo utilizando `ColumnTranformer` y `Pipeline` convenientemente anidados.\n",
    "\n",
    "En la siguiente figura podemos ver cómo será el flujo de datos en el sistema que hemos creado:\n",
    "\n",
    "![Sistema](fig_sistema.png) \n",
    "\n",
    "\n",
    "## 27.2 Podemos utilizarlo como un sistema más\n",
    "\n",
    "Hemos creado un sistema un poco más complejo, pero una vez creado podemos utilizarlo dentro de búsquedas de hiperparámetros, validaciones cruzadas,... lo que que queramos.\n",
    "\n",
    "Vamos a ver un ejemplo de uso utilizando todos los datos (no solo 5). Así que vamos a separar los atributos de la clase y luego vamos a separar los ejemplos en entrenamiento y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##########################################')\n",
    "print('### Cogemos todos los datos')\n",
    "print('##########################################')\n",
    "\n",
    "# separamos las últimas columnas y las almacenamos en X\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "# separamos la clase\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "print('\\n##########################################')\n",
    "print('### Hold-out 80-20')\n",
    "print('##########################################')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos crear una búsqueda de hiperparámetros en la que vamos a utilizar el sistema `sys_prep_svr` y vamos a buscar los mejores valores para `C` y para `gamma`, que son los hiperparámetros más importantes cuando estamos utilizando una Máquina de Vectores Soporte (SVM) de Regresión (`SVR`) con kernel `rbf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea un generador de folds partiendo el conjunto en 5 trozos\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# creamos una grid search para el SVC donde le pasamos los hiperparámetros que queremos probar\n",
    "param = {\n",
    "    'sys__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'sys__gamma': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "gs = GridSearchCV(sys_prep_svr, param_grid=param, scoring='neg_mean_squared_error', cv=folds, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la búsqueda y obtenemos el modelo con los mejores hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos\n",
    "best_model = gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor combinación de hiperparámetros:\", best_model.best_params_)\n",
    "print(\"Mejor rendimiento obtenido: %.4f\" % best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordad que el rendimiento aparece en negativo porque utilizamos `'neg_mean_squared_error'`. \n",
    "\n",
    "Ya tenemos el modelo entrenado y podemos obtener su rendimiento ante casos no vistos en el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos su rendimiento en el conjunto de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2 :\", metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Carga el conjunto de datos  **CreditApproval.data** \n",
    "2. Selecciona 5 ejemplos y vete realizando las codificaciones paso a paso como hemos visto en la práctica. Que no os asuste ver datos con caracteres, serán atributos categíricos o binarios y se tratan como ya hemos visto.\n",
    "3. Para los atributos binarios se puede utiliza `OneHotEncoder()` utilizando el parámetro `drop` convenientemente.\n",
    "4. La clase se codifica al principio, nada más cargar los datos.\n",
    "4. Una vez que veas que la codificación funciona haz una búsqueda de hiperparámetros utilizando todos los ejemplos\n",
    "\n",
    "Estos ejercicios no es necesario entregarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
